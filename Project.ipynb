{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16608ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Import core data-science libraries\n",
    "# -------------------------------------------------------------------\n",
    "import pandas as pd      # pandas → tabular data manipulation (DataFrame)\n",
    "import numpy as np       # NumPy  → fast numerical operations, arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f01c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# STEP 2 – Load the four raw CSV datasets we will later clean/merge\n",
    "# -------------------------------------------------------------------\n",
    "kag   = pd.read_csv(\"Kaggle_dataset.csv\")             # Kaggle-hosted fraud dataset (~10 k rows)\n",
    "farr  = pd.read_csv(\"Farrugia_dataset.csv\")           # Farrugia et al. 2020 labelled set (~4k rows)\n",
    "forta = pd.read_csv(\"Forta_dataset.csv\")              # Forta/Etherscan phishing–hack addresses (all illicit)\n",
    "bq    = pd.read_csv(\"BigQuery_crypto_ethereum.csv\")   # Recent Legitimate sample with BigQuery-derived features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_dataset(path: str | Path, source_name: str, illicit_flag: int | None = None):\n",
    "    \"\"\"\n",
    "    Clean and standardise a raw Ethereum-fraud CSV.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str | Path\n",
    "        Location of the CSV file to load.\n",
    "    source_name : str\n",
    "        Short identifier used in log / summary rows (e.g. \"Kaggle\").\n",
    "    illicit_flag : {0, 1} | None, optional\n",
    "        • If None   → keep / fix existing FLAG column in the file.  \n",
    "        • If 0 or 1 → force-create a constant FLAG column (useful for\n",
    "          Forta=1, BigQuery=0).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_clean : pandas.DataFrame\n",
    "        Sanitised table with a lowercase `Address` column and integer FLAG.\n",
    "    summary  : dict\n",
    "        One-line dataset summary (rows, columns, class counts, duplicates).\n",
    "    \"\"\"\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    # Load CSV into DataFrame\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Tidy column headers: strip whitespace and drop junk index cols\n",
    "    df.columns = df.columns.str.strip()\n",
    "    junk = [c for c in df.columns\n",
    "            if c.lower().startswith('unnamed') or c.lower() == 'index']\n",
    "    df.drop(columns=junk, inplace=True, errors='ignore')\n",
    "\n",
    "    # Ensure a single canonical 'Address' column in lower-case hex\n",
    "    addr_col = next((c for c in df.columns\n",
    "                     if c.lower() in {'address', 'addr'}), None)\n",
    "    if addr_col is None:\n",
    "        raise ValueError(f\"No address column detected in {source_name}\")\n",
    "    if addr_col != 'Address':\n",
    "        df.rename(columns={addr_col: 'Address'}, inplace=True)\n",
    "    df['Address'] = df['Address'].str.lower()\n",
    "\n",
    "    # Guarantee numeric FLAG column (0 = Legitimate, 1 = illicit)\n",
    "    if 'FLAG' in df.columns:\n",
    "        df['FLAG'] = df['FLAG'].fillna(0).astype(int)\n",
    "    else:\n",
    "        # For sources with only one class (e.g., Forta = illicit-only)\n",
    "        df['FLAG'] = 0 if illicit_flag is None else illicit_flag\n",
    "\n",
    "    # Remove duplicate addresses and log how many we dropped\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates('Address')\n",
    "    dups_removed = before - len(df)\n",
    "\n",
    "    # ────────────────────────────\n",
    "    # Build a tiny summary for logging / sanity checks\n",
    "    # ────────────────────────────\n",
    "    summary = dict(\n",
    "        source            = source_name,\n",
    "        rows              = len(df),\n",
    "        cols              = len(df.columns),\n",
    "        illicit_cnt       = int(df['FLAG'].sum()),\n",
    "        Legitimate_cnt        = int((df['FLAG'] == 0).sum()),\n",
    "        duplicates_removed= dups_removed\n",
    "    )\n",
    "\n",
    "    return df, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a7fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# STEP 3 – Clean every raw dataset and collect quick stats\n",
    "# -------------------------------------------------------------------\n",
    "# Mapping of dataset nick-name → file path.                     \n",
    "# (Edit here if your filenames differ.)\n",
    "files = {\n",
    "    'Kaggle'   : Path('Kaggle_dataset.csv'),\n",
    "    'Farrugia' : Path('Farrugia_dataset.csv'),\n",
    "    'Forta'    : Path('Forta_dataset.csv'),\n",
    "    'BigQuery' : Path('BigQuery_crypto_ethereum.csv')\n",
    "}\n",
    "\n",
    "cleaned    = {}   # will hold the cleaned DataFrames keyed by name\n",
    "summaries  = []   # list of one-line dicts for quick inspection\n",
    "\n",
    "for name, path in files.items():\n",
    "    # Forta list is known *all illicit*  → force FLAG = 1\n",
    "    if name == 'Forta':\n",
    "        df, s = clean_dataset(path, name, illicit_flag=1)\n",
    "\n",
    "    # BigQuery sample is treated as *all Legitimate*  → force FLAG = 0\n",
    "    elif name == 'BigQuery':\n",
    "        df, s = clean_dataset(path, name, illicit_flag=0)\n",
    "\n",
    "    # Kaggle & Farrugia already contain mixed labels\n",
    "    else:\n",
    "        df, s = clean_dataset(path, name)\n",
    "\n",
    "    cleaned[name] = df      # stash cleaned DataFrame\n",
    "    summaries.append(s)     # stash summary row\n",
    "\n",
    "# Display a tidy summary table: rows, columns, class counts, duplicates removed\n",
    "pd.DataFrame(summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# Step 1 – Aggregate total counts across all cleaned datasets\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "total_illicit = sum(s['illicit_cnt'] for s in summaries)\n",
    "total_Legitimate  = sum(s['Legitimate_cnt']  for s in summaries)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# Step 2 – Create and display the pie chart\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "labels = ['Legitimate Accounts', 'Illicit Accounts']\n",
    "sizes  = [total_Legitimate, total_illicit]\n",
    "colors = ['#66b3ff', '#ff6666']   # blue for legitimate, red for illicit\n",
    "explode = (0, 0.1)                # \"explode\" the illicit slice\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.title('Class Distribution in Unified Ethereum Dataset')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures a circular pie.\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Persist each cleaned DataFrame to disk\n",
    "# -------------------------------------------------------------------\n",
    "#   - Makes subsequent notebooks faster (no need to re-clean raw CSVs)\n",
    "#   - Gives you a frozen copy for reproducibility / sharing\n",
    "#   - Filenames follow the pattern  clean_<Source>.csv\n",
    "for name, df in cleaned.items():\n",
    "    df.to_csv(f'clean_{name}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba691b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Build a single “label registry” mapping each Address → final FLAG\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Extract only the identity and label columns from every cleaned source.\n",
    "#     (This keeps the merge logic simple and memory-efficient.)\n",
    "label_frames = [\n",
    "    cleaned['Kaggle'  ][['Address', 'FLAG']],   # mixed labels\n",
    "    cleaned['Farrugia'][['Address', 'FLAG']],   # mixed labels\n",
    "    cleaned['Forta'   ][['Address', 'FLAG']],   # all 1’s\n",
    "    cleaned['BigQuery'][['Address', 'FLAG']]    # all 0’s\n",
    "]\n",
    "\n",
    "# Concatenate the four label lists then group by Address.\n",
    "#     - Some addresses appear in more than one source with possibly\n",
    "#       conflicting labels.\n",
    "#     - Taking the *maximum* FLAG value means 1 (“illicit”) always\n",
    "#       overrides 0 (“Legitimate”) — conservative for security use-case.\n",
    "registry = (\n",
    "    pd.concat(label_frames, ignore_index=True)   # stack into one big table\n",
    "      .groupby('Address', as_index=False)['FLAG']\n",
    "      .max()                                     # 1 > 0  → illicit wins\n",
    ")\n",
    "\n",
    "# Quick sanity checks: total unique addresses and class balance\n",
    "print(\"Registry size:\", len(registry))                # e.g. 146 440\n",
    "print(registry['FLAG'].value_counts())                # 0 vs 1 counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08fdee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Build the “feature matrix” that holds engineered numeric features\n",
    "# for every address.  We start with the two sources that already\n",
    "# contain rich per-address statistics, then merge in extra metrics\n",
    "# from BigQuery.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# 5-A  Stack Kaggle and Farrugia feature tables (they share column names)\n",
    "#      - Drop FLAG because labels live in the registry now.\n",
    "tx_feats = pd.concat(\n",
    "    [\n",
    "        cleaned['Kaggle'  ].drop(columns=['FLAG']),\n",
    "        cleaned['Farrugia'].drop(columns=['FLAG'])\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# 5-B  Outer-join the additional *recent* numeric metrics that were\n",
    "#      pre-computed via BigQuery (outbound tx count, ETH sent, avg gas).\n",
    "#      outer → keep rows even if some addresses are missing these new cols\n",
    "tx_feats = tx_feats.merge(\n",
    "    cleaned['BigQuery'][['Address', 'tx_count_out', 'eth_sent', 'avg_gwei']],\n",
    "    on='Address', how='outer'\n",
    ")\n",
    "\n",
    "# 5-C  Note: Forta rows currently have NaN in these numeric columns because\n",
    "#      that CSV only had labels.  We'll replace NaNs later when we enrich\n",
    "#      Forta addresses via BigQuery — or impute with column medians.\n",
    "print(\"Feature matrix shape:\", tx_feats.shape)   # e.g. (145 k, 49 features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb5c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Merge labels ↔ features to create the final “master” dataset\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Join the label registry with the numeric/categorical feature matrix.\n",
    "# Every address now has:\n",
    "#   - Address   (primary key)\n",
    "#   - FLAG      (target label 0 / 1)\n",
    "#   - ~50 engineered features\n",
    "master = registry.merge(tx_feats, on='Address', how='left')\n",
    "\n",
    "# ── Handle missing values ──────────────────────────────────────────\n",
    "# Numeric columns → replace NaNs with the column median\n",
    "num_cols = master.select_dtypes('number').columns\n",
    "master[num_cols] = master[num_cols].fillna(master[num_cols].median())\n",
    "\n",
    "# Categorical columns (e.g., token type strings) → replace NaNs\n",
    "# with literal 'unknown' so One-Hot-Encoder has a stable category.\n",
    "cat_cols = master.select_dtypes('object').columns.difference(['Address'])\n",
    "master[cat_cols] = master[cat_cols].fillna('unknown')\n",
    "\n",
    "print(\"Master dataframe ready:\", master.shape)   # e.g. (146 440, 52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc6e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Persist the fully-cleaned, feature-complete dataset for reuse\n",
    "# -------------------------------------------------------------------\n",
    "#   - File: master_dataset_v1.csv\n",
    "#   - Rows: one per unique Ethereum address\n",
    "#   - Columns: Address, FLAG, and all engineered features\n",
    "# merging pipeline and load this single CSV instead.\n",
    "master.to_csv('master_dataset_v1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# STEP 7 – Encode categorical features & scale numeric ones\n",
    "#           Produces a ColumnTransformer stored in preprocess_v1.joblib\n",
    "# -------------------------------------------------------------------\n",
    "import pandas as pd, numpy as np, joblib\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 7-A  Separate predictors (X_raw) from target label (y)\n",
    "X_raw = master.drop(columns=['FLAG', 'Address'])  # raw feature matrix\n",
    "y     = master['FLAG'].values                     # target vector\n",
    "\n",
    "# 7-B  Identify feature types so we can apply type-specific transformers\n",
    "cat_cols = X_raw.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols = X_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numeric: {len(num_cols)}  |  Categorical: {len(cat_cols)}\")\n",
    "\n",
    "# 7-C  Define the per-type pipelines\n",
    "numeric_pipeline      = MinMaxScaler()                            # rescale 0-1\n",
    "categorical_pipeline  = OneHotEncoder(                            # one-hot encode\n",
    "    handle_unknown='ignore',      # ignore unseen categories at test-time\n",
    "    sparse_output=True            # keep sparse matrix for memory efficiency\n",
    ")\n",
    "\n",
    "# Build the unified transformer:\n",
    "#   - 'num' pipe applied to num_cols\n",
    "#   - 'cat' pipe applied to cat_cols\n",
    "#   - any leftover cols (none expected) are dropped\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, num_cols),\n",
    "        ('cat', categorical_pipeline, cat_cols)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=0.30          # keep sparse output when OHE dominates\n",
    ")\n",
    "\n",
    "# 7-D  Fit on the entire feature set so that every downstream model can\n",
    "#      share the exact same scaling / encoding parameters.\n",
    "#      (If you prefer strict train-only fitting, fit on X_train later.)\n",
    "preprocess.fit(X_raw)\n",
    "\n",
    "# 7-E  Quick sanity check: transform all rows and report shape / sparsity\n",
    "X_ready = preprocess.transform(X_raw)\n",
    "print(\"Shape after transform:\", X_ready.shape,\n",
    "      \"| Sparse matrix?:\", hasattr(X_ready, 'nnz'))\n",
    "\n",
    "# 7-F  Persist the fitted transformer; future notebooks just load it\n",
    "joblib.dump(preprocess, 'preprocess_v1.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# STEP 9  – Train / test split  +  SMOTE balancing\n",
    "# STEP 10 – Baseline model training (RF, XGB, MLP) and metric logging\n",
    "# ---------------------------------------------------------------------------\n",
    "import joblib, numpy as np, pandas as pd, warnings, gc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score,\n",
    "                             classification_report, confusion_matrix)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 9-A — Reload the fitted pre-processing pipeline (scaler + OHE)\n",
    "preprocess = joblib.load('preprocess_v1.joblib')\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Choose the hold-out strategy\n",
    "#   - time-aware  (default) :  train on Kaggle+Farrugia (≤2021),\n",
    "#                              test on Forta+BigQuery (2022-24)\n",
    "#   - random 80/20 split     :  quick sanity check\n",
    "# ------------------------------------------------------------------\n",
    "use_time_split = True      #  set False for random 80/20 baseline\n",
    "\n",
    "if use_time_split:\n",
    "    # ---------------- time-aware split ----------------\n",
    "    train_mask = master['Address'].isin(\n",
    "        pd.concat([cleaned['Kaggle'], cleaned['Farrugia']])['Address'])\n",
    "    X_train_raw = master.loc[train_mask].drop(columns=['FLAG', 'Address'])\n",
    "    y_train     = master.loc[train_mask, 'FLAG'].values\n",
    "    X_test_raw  = master.loc[~train_mask].drop(columns=['FLAG', 'Address'])\n",
    "    y_test      = master.loc[~train_mask, 'FLAG'].values\n",
    "else:\n",
    "    # ---------------- random stratified 80/20 split ----------------\n",
    "    X_raw = master.drop(columns=['FLAG', 'Address'])\n",
    "    y     = master['FLAG'].values\n",
    "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "        X_raw, y, test_size=0.20, stratify=y, random_state=42)\n",
    "\n",
    "# 9-B — Apply scaler + One-Hot encoding\n",
    "X_train = preprocess.transform(X_train_raw)\n",
    "X_test  = preprocess.transform(X_test_raw)\n",
    "\n",
    "# 9-C — Balance the *training* set only (leave test skewed)\n",
    "X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"After preprocessing + SMOTE:\"\n",
    "      f\"\\n  Train: {X_train.shape}  | illicit% = {y_train.mean():.3f}\"\n",
    "      f\"\\n  Test : {X_test.shape}   | illicit% = {y_test.mean():.3f}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# STEP 10 – Fit baseline models and evaluate on the CLEAN test set\n",
    "# ------------------------------------------------------------------\n",
    "models = {\n",
    "    \"RF\": RandomForestClassifier(\n",
    "            n_estimators=400, class_weight='balanced',\n",
    "            n_jobs=-1, random_state=42),\n",
    "\n",
    "    \"XGB\": XGBClassifier(\n",
    "            n_estimators=600, max_depth=6, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum(),\n",
    "            eval_metric='auc', n_jobs=-1, random_state=42),\n",
    "\n",
    "    \"MLP\": MLPClassifier(\n",
    "            hidden_layer_sizes=(256, 128), max_iter=30, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n────────  {name}  ────────\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    prob  = clf.predict_proba(X_test)[:, 1]           # illicit probability\n",
    "    preds = (prob >= 0.5).astype(int)                 # hard threshold 0.5\n",
    "    \n",
    "    roc   = roc_auc_score(y_test, prob)               # ROC-AUC (threshold-free)\n",
    "    prauc = average_precision_score(y_test, prob)     # PR-AUC (better for imbalance)\n",
    "    cm    = confusion_matrix(y_test, preds)\n",
    "\n",
    "    print(f\"ROC-AUC: {roc:.3f} | PR-AUC: {prauc:.3f}\")\n",
    "    print(classification_report(y_test, preds, digits=3))\n",
    "\n",
    "    results.append(dict(model=name, roc=roc, pr=prauc,\n",
    "                        TP=cm[1,1], FP=cm[0,1],\n",
    "                        FN=cm[1,0], TN=cm[0,0]))\n",
    "    \n",
    "        # Save predictions and true labels for XGB\n",
    "    if name == \"XGB\":\n",
    "        np.save(\"prob_baseline.npy\", prob)\n",
    "        np.save(\"y_test_baseline.npy\", y_test)\n",
    "\n",
    "    gc.collect()   # free RAM before next model\n",
    "\n",
    "# Save all metrics for inclusion in the dissertation tables\n",
    "pd.DataFrame(results).to_csv('baseline_metrics.csv', index=False)\n",
    "print(\"\\nSaved baseline_metrics.csv with results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5569a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the saved baseline metrics\n",
    "df = pd.read_csv(\"baseline_metrics.csv\")\n",
    "\n",
    "# Sort models in display order (optional)\n",
    "model_order = ['RF', 'XGB', 'MLP']\n",
    "df = df.set_index('model').loc[model_order].reset_index()\n",
    "\n",
    "# Plot side-by-side bars for ROC-AUC and PR-AUC\n",
    "bar_width = 0.35\n",
    "x = range(len(df))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar([i - bar_width/2 for i in x], df['roc'], width=bar_width, label='ROC-AUC', color='#4e79a7')\n",
    "plt.bar([i + bar_width/2 for i in x], df['pr'], width=bar_width, label='PR-AUC', color='#f28e2c')\n",
    "\n",
    "# X-axis labels and aesthetics\n",
    "plt.xticks(ticks=x, labels=df['model'])\n",
    "plt.ylim(0, 1.05)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Initial Baseline Model Performance (Time-Aware Split)')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ed98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "# Standalone Cell: Visualise class distribution after SMOTE\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute class counts in y_train (after SMOTE)\n",
    "illicit_count = np.sum(y_train == 1)\n",
    "Legitimate_count  = np.sum(y_train == 0)\n",
    "\n",
    "# Build pie chart\n",
    "labels = ['Legitimate Accounts (SMOTE)', 'Illicit Accounts (SMOTE)']\n",
    "sizes  = [Legitimate_count, illicit_count]\n",
    "colors = ['#66b3ff', '#ff6666']\n",
    "explode = (0, 0.1)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.title('Class Distribution in SMOTE-Balanced Training Set')\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e8d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# BigQuery enrichment script\n",
    "# Purpose: Fetch recent (2023-present) transaction statistics for the list of\n",
    "#          Forta + Legitimate BigQuery addresses and save them as a new CSV.\n",
    "# Notes:\n",
    "#   - Runs in 10 000-address batches to stay within query-parameter limits.\n",
    "#   - Prints bytes-scanned + cost estimate for each batch (assumes $5 / TB).\n",
    "#   - Requires the GCP project ‘diss-464115’ to have billing enabled.\n",
    "# ---------------------------------------------------------------------------\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd, math, time\n",
    "\n",
    "# GCP project that *runs* the query (billed here, not in public dataset)\n",
    "PROJECT_ID = \"diss-464115\"\n",
    "client     = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Load the address list exported earlier (one 0x… per line, lower-case)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "with open(\"/content/addr_list.txt\") as fh:\n",
    "    ADDR_LIST = [ln.strip().lower() for ln in fh if ln.strip()]\n",
    "\n",
    "print(\"Total addresses:\", len(ADDR_LIST))\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Parameterised SQL template (limits to 2023-01-01 → present)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "QUERY = \"\"\"\n",
    "DECLARE addrs ARRAY<STRING>;\n",
    "SET addrs = @addr_list;\n",
    "\n",
    "WITH tx AS (\n",
    "  SELECT\n",
    "    from_address   AS address,\n",
    "    value,\n",
    "    gas_price,\n",
    "    block_timestamp\n",
    "  FROM `bigquery-public-data.crypto_ethereum.transactions`\n",
    "  WHERE from_address IN UNNEST(addrs)\n",
    "        AND block_timestamp >= '2023-01-01'          -- prune partitions\n",
    ")\n",
    "SELECT\n",
    "  address                       AS Address,\n",
    "  COUNT(*)                      AS tx_count_out,    -- # outbound tx\n",
    "  SUM(value)/1e18               AS eth_sent,        -- total ETH sent\n",
    "  AVG(gas_price)/1e9            AS avg_gwei,        -- mean gas price (GWei)\n",
    "  MIN(block_timestamp)          AS first_seen,\n",
    "  MAX(block_timestamp)          AS last_seen\n",
    "FROM tx\n",
    "GROUP BY address;\n",
    "\"\"\"\n",
    "\n",
    "def query_batch(addr_chunk, idx):\n",
    "    \"\"\"\n",
    "    Run one BigQuery job for <=10 000 addresses, return result DataFrame.\n",
    "    Also print bytes-scanned and dollar cost (at $5 / TB).\n",
    "    \"\"\"\n",
    "    cfg = bigquery.QueryJobConfig(\n",
    "        query_parameters=[\n",
    "            bigquery.ArrayQueryParameter(\"addr_list\", \"STRING\", addr_chunk)\n",
    "        ]\n",
    "    )\n",
    "    job    = client.query(QUERY, job_config=cfg)\n",
    "    result = job.result()              # waits for job completion\n",
    "\n",
    "    # Cost diagnostics\n",
    "    mb   = result.total_bytes_processed / 1e6\n",
    "    cost = result.total_bytes_processed / 1e12 * 5\n",
    "    print(f\"  • Batch {idx}  scanned {mb:,.1f} MB  (~${cost:,.2f})\")\n",
    "\n",
    "    return result.to_dataframe()\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Loop over address list in 10 000-addr batches\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "batch_size = 10_000\n",
    "frames     = []\n",
    "\n",
    "for i in range(0, len(ADDR_LIST), batch_size):\n",
    "    chunk     = ADDR_LIST[i:i+batch_size]\n",
    "    batch_no  = i // batch_size + 1\n",
    "    print(f\"Batch {batch_no}/{math.ceil(len(ADDR_LIST)/batch_size)} …\")\n",
    "    frames.append(query_batch(chunk, batch_no))\n",
    "\n",
    "# Concatenate all batch DataFrames and persist to CSV\n",
    "print(\"finished all batches, assembling DataFrame …\")\n",
    "enriched_df = pd.concat(frames, ignore_index=True)\n",
    "enriched_df.to_csv(\"forta_bq_features.csv\", index=False)\n",
    "print(\"Saved forta_bq_features.csv  rows:\", len(enriched_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5668099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Merge freshly-downloaded BigQuery stats into `master`\n",
    "#   - Replaces the median-imputed placeholders for Forta & recent-Legitimate\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Load enrichment CSV and normalise address casing\n",
    "bq_new = pd.read_csv(\"forta_bq_features.csv\")\n",
    "bq_new['Address'] = bq_new['Address'].str.lower()\n",
    "\n",
    "# Define the numeric columns we expect from enrichment\n",
    "num_cols = ['tx_count_out', 'eth_sent', 'avg_gwei',\n",
    "            'first_seen', 'last_seen']\n",
    "\n",
    "# Clean up any previous *_new temp columns from earlier merges\n",
    "master.drop(columns=[c for c in master.columns if c.endswith('_new')],\n",
    "            inplace=True, errors='ignore')\n",
    "\n",
    "# Left-merge: keep all rows in master, pull in new numeric fields\n",
    "master = master.merge(bq_new, on=\"Address\", how=\"left\",\n",
    "                      suffixes=('', '_new'))  # new cols tagged with _new\n",
    "\n",
    "# For each numeric field, overwrite placeholder (old) values with\n",
    "# the real numbers when they exist in *_new; then drop the *_new col.\n",
    "for col in num_cols:\n",
    "    new_col = f\"{col}_new\"\n",
    "    if new_col in master.columns:            # only present if merge found data\n",
    "        master[col] = master[new_col].combine_first(master[col])\n",
    "        master.drop(columns=new_col, inplace=True)\n",
    "\n",
    "print(\"Master rows:\", len(master),\n",
    "      \"| tx_count_out missing:\", master['tx_count_out'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a873e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Re-fit the ColumnTransformer after merging new BigQuery features\n",
    "# Resulting pipeline is saved as preprocess_v3.joblib\n",
    "# -------------------------------------------------------------------\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "\n",
    "# Separate predictors from label / ID columns\n",
    "X_raw = master.drop(columns=['FLAG', 'Address'])\n",
    "\n",
    "# Detect data types ► which columns get which transformer\n",
    "cat_cols = X_raw.select_dtypes('object').columns.tolist()   # token names, etc.\n",
    "num_cols = X_raw.select_dtypes('number').columns.tolist()   # tx_count, eth_sent …\n",
    "\n",
    "# Build the transformer:  numeric → Min-Max ;  categorical → One-Hot (sparse)\n",
    "preprocess = ColumnTransformer([\n",
    "    ('num', MinMaxScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=True), cat_cols)\n",
    "])\n",
    "\n",
    "# Fit on the *complete* dataset so every downstream model shares\n",
    "# identical scaling / category vocabularies.\n",
    "preprocess.fit(X_raw)\n",
    "\n",
    "# Persist for reuse in training / inference notebooks\n",
    "joblib.dump(preprocess, 'preprocess_v3.joblib')\n",
    "print(\"Saved preprocess_v3.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# STEP 9 & 10 (v3)  – Training / Evaluation with enriched features\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "import joblib, numpy as np, pandas as pd, gc, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score,\n",
    "                             classification_report, confusion_matrix)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Load the latest pre-processing pipeline (includes BigQuery metrics)\n",
    "preprocess = joblib.load('preprocess_v3.joblib')\n",
    "\n",
    "# Build a *time-aware* split\n",
    "#    -  Historical addresses (≤2021) → Kaggle + Farrugia → always train\n",
    "#    -  Recent addresses (2022-24)   → Forta + BigQuery\n",
    "#       – sample 30 % into train to give model some exposure\n",
    "#       – remaining 70 % used as unseen hold-out test\n",
    "train_core_mask = master['Address'].isin(\n",
    "    pd.concat([cleaned['Kaggle'], cleaned['Farrugia']])['Address']\n",
    ")\n",
    "\n",
    "recent_mask = master['Address'].isin(\n",
    "    pd.concat([cleaned['Forta'], cleaned['BigQuery']])['Address']\n",
    ")\n",
    "recent_df = master[recent_mask]\n",
    "\n",
    "train_extra = recent_df.sample(frac=0.30, random_state=42)  # 30 % recent → train\n",
    "test_df     = recent_df.drop(train_extra.index)             # 70 % recent → test\n",
    "\n",
    "train_df = pd.concat([master[train_core_mask], train_extra], ignore_index=True)\n",
    "\n",
    "# Split predictors / labels\n",
    "X_train_raw = train_df.drop(columns=['FLAG', 'Address'])\n",
    "y_train     = train_df['FLAG'].values\n",
    "X_test_raw  = test_df.drop(columns=['FLAG', 'Address'])\n",
    "y_test      = test_df['FLAG'].values\n",
    "\n",
    "# Apply scaler+OHE, then balance training rows with SMOTE\n",
    "X_train = preprocess.transform(X_train_raw)\n",
    "X_test  = preprocess.transform(X_test_raw)\n",
    "X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Train: {X_train.shape} | illicit% {y_train.mean():.3f}\")\n",
    "print(f\"Test : {X_test.shape}  | illicit% {y_test.mean():.3f}\")\n",
    "\n",
    "# Fit three baseline models and report ROC-AUC / PR-AUC\n",
    "models = {\n",
    "    \"RF\":  RandomForestClassifier(\n",
    "              n_estimators=400, class_weight='balanced',\n",
    "              n_jobs=-1, random_state=42),\n",
    "\n",
    "    \"XGB\": XGBClassifier(\n",
    "              n_estimators=600, max_depth=6, learning_rate=0.05,\n",
    "              subsample=0.8, colsample_bytree=0.8,\n",
    "              scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
    "              eval_metric='auc', n_jobs=-1, random_state=42),\n",
    "\n",
    "    \"MLP\": MLPClassifier(\n",
    "              hidden_layer_sizes=(256,128), max_iter=40, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n──────── {name} ────────\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    prob  = clf.predict_proba(X_test)[:, 1]        # class-1 probability\n",
    "    preds = (prob >= 0.5).astype(int)              # hard threshold 0.5\n",
    "\n",
    "    roc  = roc_auc_score(y_test, prob)             # threshold-free ROC-AUC\n",
    "    pr   = average_precision_score(y_test, prob)   # PR-AUC – better for skew\n",
    "    print(f\"ROC-AUC = {roc:.3f} | PR-AUC = {pr:.3f}\")\n",
    "    print(classification_report(y_test, preds, digits=3))\n",
    "\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    results.append(dict(model=name, roc=roc, pr=pr,\n",
    "                        TP=cm[1,1], FP=cm[0,1],\n",
    "                        FN=cm[1,0], TN=cm[0,0]))\n",
    "    \n",
    "        # Save predictions and true labels for XGB\n",
    "    if name == \"XGB\":\n",
    "        np.save(\"prob_enriched.npy\", prob)\n",
    "        np.save(\"y_test_enriched.npy\", y_test)\n",
    "\n",
    "    gc.collect()   # free memory before next model\n",
    "\n",
    "# Persist metric table for Chapter 4 figures / tables\n",
    "pd.DataFrame(results).to_csv('baseline_metrics_v3.csv', index=False)\n",
    "print(\"\\nSaved baseline_metrics_v3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80108a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────\n",
    "# Load saved probabilities and labels\n",
    "# ───────────────────────────────────────────────\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prob_baseline = np.load(\"prob_baseline.npy\")\n",
    "y_test_baseline = np.load(\"y_test_baseline.npy\")\n",
    "prob_enriched = np.load(\"prob_enriched.npy\")\n",
    "y_test_enriched = np.load(\"y_test_enriched.npy\")\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# Compute ROC + PR curves\n",
    "# ───────────────────────────────────────────────\n",
    "fpr_base, tpr_base, _ = roc_curve(y_test_baseline, prob_baseline)\n",
    "fpr_enr,  tpr_enr,  _ = roc_curve(y_test_enriched,  prob_enriched)\n",
    "\n",
    "prec_base, rec_base, _ = precision_recall_curve(y_test_baseline, prob_baseline)\n",
    "prec_enr,  rec_enr,  _ = precision_recall_curve(y_test_enriched,  prob_enriched)\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# Plot: ROC and PR side by side\n",
    "# ───────────────────────────────────────────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# ROC\n",
    "axes[0].plot(fpr_enr, tpr_enr, label='BigQuery Enriched', color='#1b9e77', linewidth=2)\n",
    "axes[0].plot(fpr_base, tpr_base, label='Initial Baseline', color='grey', linestyle='--')\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.5)\n",
    "axes[0].set_title(\"ROC Curve – XGBoost\")\n",
    "axes[0].set_xlabel(\"False Positive Rate\")\n",
    "axes[0].set_ylabel(\"True Positive Rate\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# PR\n",
    "axes[1].plot(rec_enr, prec_enr, label='BigQuery Enriched', color='#1b9e77', linewidth=2)\n",
    "axes[1].plot(rec_base, prec_base, label='Initial Baseline', color='grey', linestyle='--')\n",
    "axes[1].set_title(\"Precision-Recall Curve – XGBoost\")\n",
    "axes[1].set_xlabel(\"Recall\")\n",
    "axes[1].set_ylabel(\"Precision\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"XGBoost ROC and PR Curves: BigQuery vs Baseline\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53504b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Build the transaction edge list for graph-based feature engineering\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "#     Upload the list of all addresses in `master` to BigQuery as a\n",
    "#     *temporary* table (tmp.master_addresses).\n",
    "#     - Makes the downstream edge query fast because we can use an IN clause\n",
    "#       instead of passing a huge Python list.\n",
    "addr_df = master[['Address']]\n",
    "addr_df.to_gbq(\n",
    "    'tmp.master_addresses',          # dataset.table in your GCP project\n",
    "    project_id=PROJECT_ID,           # e.g. \"diss-464115\"\n",
    "    if_exists='replace'              # overwrite in case table already exists\n",
    ")\n",
    "\n",
    "#     Query the public Ethereum transactions table for edges *only* between\n",
    "#     addresses that appear in our master list, limited to 2023-01-01 onward\n",
    "#     to keep the scan cost small.\n",
    "GQUERY = \"\"\"\n",
    "WITH addrs AS (\n",
    "  SELECT LOWER(Address) AS addr\n",
    "  FROM   `tmp.master_addresses`\n",
    ")\n",
    "SELECT\n",
    "  LOWER(from_address) AS src,      -- source node\n",
    "  LOWER(to_address)   AS dst       -- destination node\n",
    "FROM `bigquery-public-data.crypto_ethereum.transactions`\n",
    "WHERE block_timestamp >= '2023-01-01'            -- 2-year window\n",
    "  AND from_address IN (SELECT addr FROM addrs)   -- both endpoints in master\n",
    "  AND to_address   IN (SELECT addr FROM addrs)\n",
    "\"\"\"\n",
    "\n",
    "# Run the query, materialise result into a local DataFrame,\n",
    "# and persist as CSV for later NetworkX processing.\n",
    "edge_df = client.query(GQUERY).result().to_dataframe()\n",
    "edge_df.to_csv('edge_list.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ea383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx, pandas as pd\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# STEP 8-B – Construct the transaction graph and compute core\n",
    "#            network-centrality metrics for every address node.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "#  Load the <src , dst> edge list extracted via BigQuery\n",
    "edges = pd.read_csv('edge_list.csv')\n",
    "\n",
    "#  Build a directed graph G where:\n",
    "#       - nodes = Ethereum addresses present in master\n",
    "#       - edges = ETH transfers between those addresses (2023-24 window)\n",
    "G = nx.from_pandas_edgelist(\n",
    "        edges,\n",
    "        source='src',\n",
    "        target='dst',\n",
    "        create_using=nx.DiGraph()\n",
    "     )\n",
    "\n",
    "print(\"Graph:\", G.number_of_nodes(), \"nodes –\", G.number_of_edges(), \"edges\")\n",
    "\n",
    "#  Compute node-level features\n",
    "#     - out/in-degree  : simple transactional activity\n",
    "#     - PageRank       : global importance / centrality\n",
    "#     - Betweenness    : bridge-likeness (sampled for speed, k=400)\n",
    "deg_out  = dict(G.out_degree())                              # # tx sent\n",
    "deg_in   = dict(G.in_degree())                               # # tx received\n",
    "pagerank = nx.pagerank(G, alpha=0.85)                        # power-iteration\n",
    "between  = nx.betweenness_centrality(G, k=400, seed=42)      # sampled approx.\n",
    "\n",
    "#  Assemble into a DataFrame keyed by Address\n",
    "graph_feat = pd.DataFrame({\n",
    "    'Address'   : list(G.nodes()),\n",
    "    'out_deg'   : pd.Series(deg_out),\n",
    "    'in_deg'    : pd.Series(deg_in),\n",
    "    'pagerank'  : pd.Series(pagerank),\n",
    "    'betweenness': pd.Series(between)\n",
    "})\n",
    "\n",
    "#  Persist to CSV – will be merged into master and normalised later\n",
    "graph_feat.to_csv('graph_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be512680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Merge graph-centrality metrics into `master` and rebuild the\n",
    "# pre-processing pipeline (now v4) that includes these new features.\n",
    "# -------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "#  Join the graph feature table to the master dataset on Address\n",
    "gfeat = pd.read_csv('graph_features.csv')\n",
    "master = master.merge(gfeat, on='Address', how='left')\n",
    "\n",
    "#     Any address that had no outgoing / incoming edge in the 2023-24\n",
    "#     sub-graph will have NaN in the new columns — set those to zero.\n",
    "for col in ['out_deg', 'in_deg', 'pagerank', 'betweenness']:\n",
    "    master[col] = master[col].fillna(0)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Re-fit ColumnTransformer  ->  preprocess_v4.joblib\n",
    "#   - Adds the 4 graph metrics to the numeric pipeline\n",
    "# -------------------------------------------------------------------\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib, numpy as np\n",
    "\n",
    "# Split predictors from ID / target\n",
    "X_raw = master.drop(columns=['FLAG', 'Address'])\n",
    "\n",
    "# Detect column types\n",
    "cat_cols = X_raw.select_dtypes('object').columns.tolist()   # categorical\n",
    "num_cols = X_raw.select_dtypes('number').columns.tolist()   # numeric (incl. 4 graph feats)\n",
    "\n",
    "# Build & fit the transformer\n",
    "preprocess = ColumnTransformer([\n",
    "    ('num', MinMaxScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=True), cat_cols)\n",
    "])\n",
    "preprocess.fit(X_raw)\n",
    "\n",
    "# Persist as v4 (graph-enhanced) — subsequent modelling code will load this\n",
    "joblib.dump(preprocess, 'preprocess_v4.joblib')\n",
    "print(\"Saved preprocess_v4.joblib  (includes graph features)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d87118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Load the latest pre-processing pipeline (v4) that now includes\n",
    "# min-max scaling, one-hot encoding, *and* the four graph-centrality\n",
    "# columns added in the previous step. All subsequent training /\n",
    "# inference will reuse these exact transformations.\n",
    "# -------------------------------------------------------------------\n",
    "preprocess = joblib.load('preprocess_v4.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# STEP 9 & 10  (graph-enhanced baseline)\n",
    "#   - Uses preprocess_v4.joblib  – includes both transactional & graph features\n",
    "#   - Time-aware split:   train = Kaggle+Farrugia + 30 % of recent   \n",
    "#                         test  = remaining 70 % recent (Forta+BigQuery)\n",
    "#   - Balances training data with SMOTE\n",
    "#   - Trains three baseline models (RF, XGB, MLP) and logs metrics\n",
    "# ---------------------------------------------------------------------------\n",
    "import joblib, gc, warnings, numpy as np, pandas as pd\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score,\n",
    "                             classification_report, confusion_matrix)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the pre-fitted transformer that handles scaling + OHE + graph cols\n",
    "preprocess = joblib.load('preprocess_v4.joblib')\n",
    "\n",
    "# ---------  Build a time-aware train / test split  -------------------\n",
    "#      - Historical core (≤ 2021) → always in training\n",
    "#      - Recent addresses (2022-24) → 30 % into training, 70 % held out\n",
    "train_core_mask = master['Address'].isin(\n",
    "    pd.concat([cleaned['Kaggle'], cleaned['Farrugia']])['Address']\n",
    ")\n",
    "\n",
    "recent_mask = master['Address'].isin(\n",
    "    pd.concat([cleaned['Forta'], cleaned['BigQuery']])['Address']\n",
    ")\n",
    "recent_df   = master[recent_mask]\n",
    "\n",
    "train_extra = recent_df.sample(frac=0.30, random_state=42)   # 30 % recent\n",
    "test_df     = recent_df.drop(train_extra.index)              # 70 % recent\n",
    "\n",
    "train_df = pd.concat([master[train_core_mask], train_extra], ignore_index=True)\n",
    "\n",
    "# Split predictors / labels\n",
    "X_train = preprocess.transform(train_df.drop(columns=['FLAG', 'Address']))\n",
    "y_train = train_df['FLAG'].values\n",
    "\n",
    "X_test  = preprocess.transform(test_df.drop(columns=['FLAG', 'Address']))\n",
    "y_test  = test_df['FLAG'].values\n",
    "\n",
    "# Balance the minority class in TRAIN set only with SMOTE\n",
    "X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Train: {X_train.shape}  illicit% {y_train.mean():.3f}\")\n",
    "print(f\"Test : {X_test.shape}   illicit% {y_test.mean():.3f}\")\n",
    "\n",
    "# Define three baseline learners\n",
    "models = {\n",
    "    \"RF\" : RandomForestClassifier(\n",
    "              n_estimators=400, class_weight='balanced',\n",
    "              n_jobs=-1, random_state=42),\n",
    "\n",
    "    \"XGB\": XGBClassifier(\n",
    "              n_estimators=600, max_depth=6, learning_rate=0.05,\n",
    "              subsample=0.8, colsample_bytree=0.8,\n",
    "              scale_pos_weight = (y_train==0).sum() / (y_train==1).sum(),\n",
    "              eval_metric='auc', n_jobs=-1, random_state=42),\n",
    "\n",
    "    \"MLP\": MLPClassifier(\n",
    "              hidden_layer_sizes=(256,128),\n",
    "              max_iter=40, random_state=42)\n",
    "}\n",
    "\n",
    "# Train -> evaluate -> collect metrics for each model\n",
    "results = []\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n──────── {name} ────────\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    prob  = clf.predict_proba(X_test)[:, 1]         # P(illicit)\n",
    "    preds = (prob >= 0.5).astype(int)               # threshold @ 0.5\n",
    "\n",
    "    roc  = roc_auc_score(y_test, prob)              # ROC-AUC\n",
    "    pr   = average_precision_score(y_test, prob)    # PR-AUC (class-imbalance)\n",
    "    print(f\"ROC-AUC = {roc:.3f} | PR-AUC = {pr:.3f}\")\n",
    "    print(classification_report(y_test, preds, digits=3))\n",
    "\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    results.append(dict(model=name, roc=roc, pr=pr,\n",
    "                        TP=cm[1,1], FP=cm[0,1],\n",
    "                        FN=cm[1,0], TN=cm[0,0]))\n",
    "    \n",
    "    # SAVE each trained model so visual-pack can reload them\n",
    "    if name == \"RF\":\n",
    "        joblib.dump(clf, 'clf_rf.joblib')\n",
    "    elif name == \"XGB\":\n",
    "        joblib.dump(clf, 'clf_xgb.joblib')\n",
    "    elif name == \"MLP\":\n",
    "        joblib.dump(clf, 'clf_mlp.joblib')\n",
    "\n",
    "    gc.collect()    # free GPU / CPU RAM before next model\n",
    "\n",
    "# Save metrics table for Chapter 4 results section and test split\n",
    "pd.DataFrame(results).to_csv(\"baseline_metrics_v4.csv\", index=False)\n",
    "test_df.to_csv(\"test_split_v4.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved baseline_metrics_v4.csv, test_split_v4.csv, and model joblib files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ecd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# Load model metrics from both phases\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "v3 = pd.read_csv(\"baseline_metrics_v3.csv\")  # BigQuery enriched\n",
    "v4 = pd.read_csv(\"baseline_metrics_v4.csv\")  # Graph-enhanced\n",
    "\n",
    "# Merge into a single comparison DataFrame\n",
    "v3['phase'] = 'BigQuery Only'\n",
    "v4['phase'] = 'Graph + BigQuery'\n",
    "\n",
    "df = pd.concat([v3, v4], ignore_index=True)\n",
    "df = df[df['model'].isin(['RF', 'XGB', 'MLP'])]  # Consistent model ordering\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# Plot: Bar chart for ROC-AUC and PR-AUC by model + phase\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "bar_width = 0.35\n",
    "x_labels = ['RF', 'XGB', 'MLP']\n",
    "x = np.arange(len(x_labels))\n",
    "\n",
    "# Extract per-phase scores\n",
    "roc_v3 = v3.set_index('model').loc[x_labels]['roc'].values\n",
    "roc_v4 = v4.set_index('model').loc[x_labels]['roc'].values\n",
    "pr_v3  = v3.set_index('model').loc[x_labels]['pr'].values\n",
    "pr_v4  = v4.set_index('model').loc[x_labels]['pr'].values\n",
    "\n",
    "# Plot ROC-AUC comparison\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(x - bar_width/2, roc_v3, bar_width, label='BigQuery Only', color='#1b9e77')\n",
    "plt.bar(x + bar_width/2, roc_v4, bar_width, label='Graph + BigQuery', color='#d95f02')\n",
    "plt.xticks(x, x_labels)\n",
    "plt.ylabel(\"ROC-AUC\")\n",
    "plt.ylim(0.4, 1.05)\n",
    "plt.title(\"ROC-AUC Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# Plot PR-AUC comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(x - bar_width/2, pr_v3, bar_width, label='BigQuery Only', color='#1b9e77')\n",
    "plt.bar(x + bar_width/2, pr_v4, bar_width, label='Graph + BigQuery', color='#d95f02')\n",
    "plt.xticks(x, x_labels)\n",
    "plt.ylabel(\"PR-AUC\")\n",
    "plt.ylim(0.4, 1.05)\n",
    "plt.title(\"PR-AUC Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.suptitle(\"Model Performance: BigQuery vs Graph-Augmented Features\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# STEP 1: Rebuild clean master dataset\n",
    "# ================================================================\n",
    "import pandas as pd\n",
    "\n",
    "# Load cleaned datasets\n",
    "kag   = pd.read_csv(\"clean_Kaggle.csv\")\n",
    "farr  = pd.read_csv(\"clean_Farrugia.csv\")\n",
    "forta = pd.read_csv(\"clean_Forta.csv\")\n",
    "bq    = pd.read_csv(\"clean_BigQuery.csv\")\n",
    "\n",
    "# Build label registry\n",
    "label_frames = [\n",
    "    kag[[\"Address\",\"FLAG\"]],\n",
    "    farr[[\"Address\",\"FLAG\"]],\n",
    "    forta[[\"Address\",\"FLAG\"]],\n",
    "    bq[[\"Address\",\"FLAG\"]]\n",
    "]\n",
    "registry = (\n",
    "    pd.concat(label_frames, ignore_index=True)\n",
    "      .groupby(\"Address\", as_index=False)[\"FLAG\"]\n",
    "      .max()\n",
    ")\n",
    "\n",
    "# Build transactional feature matrix\n",
    "tx_feats = pd.concat(\n",
    "    [kag.drop(columns=[\"FLAG\"]),\n",
    "     farr.drop(columns=[\"FLAG\"])],\n",
    "    ignore_index=True\n",
    ")\n",
    "tx_feats = tx_feats.merge(\n",
    "    bq.drop(columns=[\"FLAG\"]),\n",
    "    on=\"Address\", how=\"outer\"\n",
    ")\n",
    "\n",
    "# Merge labels and features\n",
    "master = registry.merge(tx_feats, on=\"Address\", how=\"left\")\n",
    "\n",
    "# Fill numeric NaNs\n",
    "num_cols = master.select_dtypes(\"number\").columns\n",
    "master[num_cols] = master[num_cols].fillna(master[num_cols].median())\n",
    "\n",
    "# Fill categorical NaNs\n",
    "cat_cols = master.select_dtypes(\"object\").columns.difference([\"Address\"])\n",
    "master[cat_cols] = master[cat_cols].fillna(\"unknown\")\n",
    "\n",
    "# Save for reproducibility\n",
    "master.to_csv(\"master_dataset_node2vec_base.csv\", index=False)\n",
    "print(\"master_dataset_node2vec_base.csv saved:\", master.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# STEP 2: Node2Vec embedding generation\n",
    "# ================================================================\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "# Load edge list\n",
    "edges = pd.read_csv(\"edge_list.csv\")\n",
    "G = nx.from_pandas_edgelist(edges, source=\"src\", target=\"dst\", create_using=nx.DiGraph())\n",
    "\n",
    "print(\"Graph nodes:\", G.number_of_nodes(), \"| edges:\", G.number_of_edges())\n",
    "\n",
    "# Train Node2Vec\n",
    "node2vec = Node2Vec(\n",
    "    G, dimensions=64, walk_length=10, num_walks=50, workers=2, seed=42\n",
    ")\n",
    "model = node2vec.fit(window=5, min_count=1, batch_words=4)\n",
    "\n",
    "# Create embedding DataFrame\n",
    "embeddings = []\n",
    "for node in G.nodes():\n",
    "    vec = model.wv.get_vector(node)\n",
    "    embeddings.append([node] + vec.tolist())\n",
    "\n",
    "cols = [\"Address\"] + [f\"n2v_{i}\" for i in range(64)]\n",
    "embed_df = pd.DataFrame(embeddings, columns=cols)\n",
    "\n",
    "# Save embeddings\n",
    "embed_df.to_csv(\"node2vec_embeddings.csv\", index=False)\n",
    "print(\"node2vec_embeddings.csv saved:\", embed_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# STEP 3: Merge Node2Vec embeddings\n",
    "# ================================================================\n",
    "import pandas as pd\n",
    "\n",
    "# Load base master\n",
    "master = pd.read_csv(\"master_dataset_node2vec_base.csv\")\n",
    "print(\"Master loaded:\", master.shape)\n",
    "\n",
    "# Load embeddings\n",
    "embed = pd.read_csv(\"node2vec_embeddings.csv\")\n",
    "embed[\"Address\"] = embed[\"Address\"].str.lower()\n",
    "\n",
    "# Merge\n",
    "master = master.merge(embed, on=\"Address\", how=\"left\")\n",
    "\n",
    "# Fill embedding NaNs with 0\n",
    "embed_cols = [c for c in master.columns if c.startswith(\"n2v_\")]\n",
    "master[embed_cols] = master[embed_cols].fillna(0)\n",
    "\n",
    "# Save\n",
    "master.to_csv(\"master_dataset_node2vec.csv\", index=False)\n",
    "print(\"master_dataset_node2vec.csv saved:\", master.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4824c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# STEP 4: Strict Address-Based Split\n",
    "# ================================================================\n",
    "import numpy as np\n",
    "\n",
    "# Load master\n",
    "master = pd.read_csv(\"master_dataset_node2vec.csv\")\n",
    "\n",
    "# Get unique addresses\n",
    "unique_addrs = master[\"Address\"].unique()\n",
    "print(\"Total unique addresses:\", len(unique_addrs))\n",
    "\n",
    "# Random split\n",
    "rng = np.random.RandomState(42)\n",
    "train_addrs = rng.choice(unique_addrs, size=int(0.6*len(unique_addrs)), replace=False)\n",
    "test_addrs  = np.setdiff1d(unique_addrs, train_addrs)\n",
    "\n",
    "# Confirm disjoint\n",
    "assert len(set(train_addrs) & set(test_addrs)) == 0\n",
    "\n",
    "# Build splits\n",
    "train_df = master[master[\"Address\"].isin(train_addrs)].reset_index(drop=True)\n",
    "test_df  = master[master[\"Address\"].isin(test_addrs)].reset_index(drop=True)\n",
    "\n",
    "# Save for reproducibility\n",
    "train_df.to_csv(\"train_node2vec.csv\", index=False)\n",
    "test_df.to_csv(\"test_node2vec.csv\", index=False)\n",
    "\n",
    "print(\"Train/Test split saved.\")\n",
    "print(\"Train rows:\", len(train_df), \"| Test rows:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31996572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# STEP 5: Preprocessing + Model Training (Leak-Free)\n",
    "# ================================================================\n",
    "import pandas as pd, numpy as np, gc, joblib\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Load splits\n",
    "train_df = pd.read_csv(\"train_node2vec.csv\")\n",
    "test_df  = pd.read_csv(\"test_node2vec.csv\")\n",
    "\n",
    "# Prepare columns\n",
    "drop_cols = [\"FLAG\", \"Address\"]\n",
    "\n",
    "X_train_raw = train_df.drop(columns=drop_cols)\n",
    "y_train     = train_df[\"FLAG\"].values\n",
    "\n",
    "X_test_raw  = test_df.drop(columns=drop_cols)\n",
    "y_test      = test_df[\"FLAG\"].values\n",
    "\n",
    "# Preprocessing\n",
    "cat_cols = X_train_raw.select_dtypes(\"object\").columns.tolist()\n",
    "num_cols = X_train_raw.select_dtypes(\"number\").columns.tolist()\n",
    "\n",
    "X_train_raw[num_cols] = X_train_raw[num_cols].fillna(0)\n",
    "X_test_raw[num_cols]  = X_test_raw[num_cols].fillna(0)\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", MinMaxScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_cols)\n",
    "])\n",
    "\n",
    "preprocess.fit(X_train_raw)\n",
    "joblib.dump(preprocess, \"preprocess_node2vec.joblib\")\n",
    "print(\"Fitted preprocess on train only.\")\n",
    "\n",
    "# Transform (dense + NaN safe)\n",
    "def transform_dense(X):\n",
    "    Xp = preprocess.transform(X)\n",
    "    if hasattr(Xp, \"toarray\"):\n",
    "        Xp = Xp.toarray()\n",
    "    return np.nan_to_num(Xp, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "X_train = transform_dense(X_train_raw)\n",
    "X_test  = transform_dense(X_test_raw)\n",
    "\n",
    "# Balance training set\n",
    "X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "print(\"Train balanced:\", X_train.shape, \"| % illicit:\", y_train.mean())\n",
    "\n",
    "# Train models\n",
    "models = {\n",
    "    \"RF\": RandomForestClassifier(\n",
    "        n_estimators=400, class_weight=\"balanced\",\n",
    "        n_jobs=-1, random_state=42),\n",
    "\n",
    "    \"XGB\": XGBClassifier(\n",
    "        n_estimators=600, max_depth=6, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
    "        eval_metric=\"auc\", n_jobs=-1, random_state=42),\n",
    "\n",
    "    \"MLP\": MLPClassifier(\n",
    "        hidden_layer_sizes=(256,128), max_iter=40, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    prob = clf.predict_proba(X_test)[:,1]\n",
    "    preds = (prob >= 0.5).astype(int)\n",
    "\n",
    "    roc = roc_auc_score(y_test, prob)\n",
    "    pr  = average_precision_score(y_test, prob)\n",
    "\n",
    "    print(f\"ROC-AUC: {roc:.3f} | PR-AUC: {pr:.3f}\")\n",
    "    print(classification_report(y_test, preds, digits=3))\n",
    "\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    results.append(dict(model=name, roc=roc, pr=pr,\n",
    "                        TP=cm[1,1], FP=cm[0,1],\n",
    "                        FN=cm[1,0], TN=cm[0,0]))\n",
    "\n",
    "    joblib.dump(clf, f\"clf_node2vec_{name.lower()}.joblib\")\n",
    "    gc.collect()\n",
    "\n",
    "# Save metrics\n",
    "pd.DataFrame(results).to_csv(\"node2vec_metrics.csv\", index=False)\n",
    "print(\"Saved node2vec_metrics.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Reload test data\n",
    "test_df = pd.read_csv(\"test_node2vec.csv\")\n",
    "y_test = test_df[\"FLAG\"].values\n",
    "\n",
    "# Reload preprocessing\n",
    "preprocess = joblib.load(\"preprocess_node2vec.joblib\")\n",
    "X_test_raw = test_df.drop(columns=[\"FLAG\", \"Address\"])\n",
    "\n",
    "# Handle transformation\n",
    "def transform_dense(X):\n",
    "    Xp = preprocess.transform(X)\n",
    "    return Xp.toarray() if hasattr(Xp, \"toarray\") else Xp\n",
    "\n",
    "X_test = transform_dense(X_test_raw)\n",
    "\n",
    "# Reload models\n",
    "models = {\n",
    "    \"RF\": joblib.load(\"clf_node2vec_rf.joblib\"),\n",
    "    \"XGB\": joblib.load(\"clf_node2vec_xgb.joblib\"),\n",
    "    \"MLP\": joblib.load(\"clf_node2vec_mlp.joblib\")\n",
    "}\n",
    "\n",
    "# Store scores\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    preds = model.predict(X_test)\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "    precision_scores.append(report[\"1\"][\"precision\"])\n",
    "    recall_scores.append(report[\"1\"][\"recall\"])\n",
    "    f1_scores.append(report[\"1\"][\"f1-score\"])\n",
    "\n",
    "# Stacked bar plot\n",
    "labels = list(models.keys())\n",
    "x = np.arange(len(labels))\n",
    "bar_width = 0.6\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(x, precision_scores, width=bar_width, label='Precision', color='#1f77b4')\n",
    "plt.bar(x, recall_scores, width=bar_width, bottom=precision_scores, label='Recall', color='#ff7f0e')\n",
    "bottoms = np.array(precision_scores) + np.array(recall_scores)\n",
    "plt.bar(x, f1_scores, width=bar_width, bottom=bottoms, label='F1-Score', color='#2ca02c')\n",
    "\n",
    "plt.xticks(x, labels)\n",
    "plt.ylim(0, 2.5)\n",
    "plt.ylabel(\"Score (stacked)\")\n",
    "plt.title(\"Precision, Recall, and F1 per Model (Illicit Class)\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409c65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Subplot 1: ROC\n",
    "plt.subplot(1, 2, 1)\n",
    "for name, model in models.items():\n",
    "    prob = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, prob)\n",
    "    plt.plot(fpr, tpr, label=name)\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.4)\n",
    "plt.title(\"ROC Curves – Hybrid Feature Models\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Subplot 2: Precision-Recall\n",
    "plt.subplot(1, 2, 2)\n",
    "for name, model in models.items():\n",
    "    prob = model.predict_proba(X_test)[:, 1]\n",
    "    prec, rec, _ = precision_recall_curve(y_test, prob)\n",
    "    plt.plot(rec, prec, label=name)\n",
    "plt.title(\"Precision-Recall Curves – Hybrid Feature Models\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"Hybrid Features (Transactional + Node2Vec): Model Comparison\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856145ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Node2Vec Embeddings Only (RF, XGB, MLP)\n",
    "# ================================================================\n",
    "import pandas as pd, numpy as np, joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load train/test splits\n",
    "train_df = pd.read_csv(\"train_node2vec.csv\")\n",
    "test_df  = pd.read_csv(\"test_node2vec.csv\")\n",
    "\n",
    "# Select embedding columns\n",
    "embed_cols = [c for c in train_df.columns if c.startswith(\"n2v_\")]\n",
    "X_train_raw, y_train = train_df[embed_cols], train_df[\"FLAG\"].values\n",
    "X_test_raw,  y_test  = test_df[embed_cols],  test_df[\"FLAG\"].values\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler().fit(X_train_raw)\n",
    "X_train, X_test = scaler.transform(X_train_raw), scaler.transform(X_test_raw)\n",
    "\n",
    "# Balance training set\n",
    "X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=400, class_weight=\"balanced\", n_jobs=-1, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=600, max_depth=6, learning_rate=0.05,\n",
    "                             subsample=0.8, colsample_bytree=0.8,\n",
    "                             scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
    "                             eval_metric=\"auc\", n_jobs=-1, random_state=42),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(256,128), max_iter=40, random_state=42)\n",
    "}\n",
    "\n",
    "# Train, evaluate, and save\n",
    "results = []\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n=== {name} (Embeddings Only) ===\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    prob  = clf.predict_proba(X_test)[:,1]\n",
    "    preds = (prob >= 0.5).astype(int)\n",
    "\n",
    "    roc, pr = roc_auc_score(y_test, prob), average_precision_score(y_test, prob)\n",
    "    print(f\"ROC-AUC: {roc:.3f} | PR-AUC: {pr:.3f}\")\n",
    "    print(classification_report(y_test, preds))\n",
    "\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    results.append(dict(model=name, roc=roc, pr=pr,\n",
    "                        TP=cm[1,1], FP=cm[0,1],\n",
    "                        FN=cm[1,0], TN=cm[0,0]))\n",
    "\n",
    "    joblib.dump(clf, f\"clf_embeddings_{name.lower()}.joblib\")\n",
    "\n",
    "# Save metrics\n",
    "pd.DataFrame(results).to_csv(\"embeddings_only_metrics.csv\", index=False)\n",
    "print(\"\\nResults saved to embeddings_only_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff829f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Evaluate Saved Models (Node2Vec Embeddings Only)\n",
    "# ================================================================\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns, joblib\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load test set and isolate embeddings\n",
    "test_df = pd.read_csv(\"test_node2vec.csv\")\n",
    "embed_cols = [c for c in test_df.columns if c.startswith(\"n2v_\")]\n",
    "X_test_raw, y_test = test_df[embed_cols], test_df[\"FLAG\"].values\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler().fit(X_test_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "# Reload trained models\n",
    "models = {\n",
    "    \"RandomForest\": joblib.load(\"clf_embeddings_randomforest.joblib\"),\n",
    "    \"XGBoost\": joblib.load(\"clf_embeddings_xgboost.joblib\"),\n",
    "    \"MLP\": joblib.load(\"clf_embeddings_mlp.joblib\")\n",
    "}\n",
    "\n",
    "# Confusion matrices\n",
    "plt.figure(figsize=(15, 4))\n",
    "labels = [\"Legitimate\", \"Illicit\"]\n",
    "for i, (name, model) in enumerate(models.items(), start=1):\n",
    "    preds = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Reds\",\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f\"{name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "plt.suptitle(\"Confusion Matrices – Embeddings Only\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Precision–Recall curves\n",
    "plt.figure(figsize=(7.5, 6))\n",
    "for name, model in models.items():\n",
    "    prob = model.predict_proba(X_test)[:, 1]\n",
    "    prec, rec, _ = precision_recall_curve(y_test, prob)\n",
    "    plt.plot(rec, prec, label=name)\n",
    "plt.title(\"PR Curves – Embeddings Only\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Randomized Labels Test (RF, XGB, MLP)\n",
    "# ================================================================\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Shuffle labels\n",
    "y_train_random = y_train.copy()\n",
    "np.random.shuffle(y_train_random)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=400, class_weight=\"balanced\", n_jobs=-1, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=600, max_depth=6, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
    "        eval_metric=\"auc\", n_jobs=-1, random_state=42),\n",
    "    \"MLP\": MLPClassifier(\n",
    "        hidden_layer_sizes=(256,128), max_iter=40, random_state=42)\n",
    "}\n",
    "\n",
    "# Train + evaluate\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n=== {name} (Randomized Labels) ===\")\n",
    "    clf.fit(X_train, y_train_random)\n",
    "    prob  = clf.predict_proba(X_test)[:,1]\n",
    "    preds = (prob >= 0.5).astype(int)\n",
    "\n",
    "    roc, pr = roc_auc_score(y_test, prob), average_precision_score(y_test, prob)\n",
    "    print(f\"ROC-AUC: {roc:.3f} | PR-AUC: {pr:.3f}\\n\")\n",
    "    print(classification_report(y_test, preds, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb80059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ROC Curves – Randomized Labels\n",
    "# ================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Plot ROC for each model\n",
    "plt.figure(figsize=(7, 6))\n",
    "for name, clf in models.items():\n",
    "    prob = clf.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, prob)\n",
    "    plt.plot(fpr, tpr, label=name)\n",
    "\n",
    "# Add random baseline\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray', label=\"Random Guess\")\n",
    "\n",
    "# Style\n",
    "plt.title(\"ROC Curves – Randomized Labels\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f254aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Count Unique Addresses per Source\n",
    "# ================================================================\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "kaggle_df = pd.read_csv(\"clean_Kaggle.csv\")\n",
    "farr_df   = pd.read_csv(\"clean_Farrugia.csv\")\n",
    "forta_df  = pd.read_csv(\"clean_Forta.csv\")\n",
    "\n",
    "# Extract lowercase address sets\n",
    "kaggle_addrs = set(kaggle_df[\"Address\"].str.lower())\n",
    "farr_addrs   = set(farr_df[\"Address\"].str.lower())\n",
    "forta_addrs  = set(forta_df[\"Address\"].str.lower())\n",
    "\n",
    "# Print counts\n",
    "print(\"Unique addresses per client:\")\n",
    "print(\"Kaggle:\", len(kaggle_addrs))\n",
    "print(\"Farrugia:\", len(farr_addrs))\n",
    "print(\"Forta:\", len(forta_addrs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Edge Counts per Client\n",
    "# ================================================================\n",
    "# Load edge list + lowercase\n",
    "edges = pd.read_csv(\"edge_list.csv\")\n",
    "edges[\"src\"], edges[\"dst\"] = edges[\"src\"].str.lower(), edges[\"dst\"].str.lower()\n",
    "\n",
    "# Subgraphs by client source nodes\n",
    "edges_kaggle = edges[edges[\"src\"].isin(kaggle_addrs)]\n",
    "edges_farr   = edges[edges[\"src\"].isin(farr_addrs)]\n",
    "edges_forta  = edges[edges[\"src\"].isin(forta_addrs)]\n",
    "\n",
    "# Print counts\n",
    "print(\"Edges per client:\")\n",
    "print(\"Kaggle:\", len(edges_kaggle))\n",
    "print(\"Farrugia:\", len(edges_farr))\n",
    "print(\"Forta:\", len(edges_forta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Train Node2Vec Embeddings per Client\n",
    "# ================================================================\n",
    "from node2vec import Node2Vec\n",
    "import networkx as nx\n",
    "\n",
    "def train_node2vec(edge_df, name):\n",
    "    print(f\"\\n=== Training Node2Vec for {name} ===\")\n",
    "\n",
    "    # Build directed graph\n",
    "    G = nx.from_pandas_edgelist(edge_df, \"src\", \"dst\", create_using=nx.DiGraph())\n",
    "\n",
    "    # Train Node2Vec\n",
    "    model = Node2Vec(G, dimensions=64, walk_length=10,\n",
    "                     num_walks=30, workers=2).fit()\n",
    "\n",
    "    # Collect embeddings\n",
    "    embeddings = [[node] + model.wv.get_vector(node).tolist()\n",
    "                  for node in G.nodes()]\n",
    "\n",
    "    # Save to CSV\n",
    "    cols = [\"Address\"] + [f\"{name}_emb_{i}\" for i in range(64)]\n",
    "    embed_df = pd.DataFrame(embeddings, columns=cols)\n",
    "    embed_df.to_csv(f\"embed_{name}.csv\", index=False)\n",
    "    print(f\"Saved embed_{name}.csv: shape {embed_df.shape}\")\n",
    "\n",
    "    return embed_df\n",
    "\n",
    "# Train per client\n",
    "embed_kaggle = train_node2vec(edges_kaggle, \"kaggle\")\n",
    "embed_farr   = train_node2vec(edges_farr, \"farrugia\")\n",
    "embed_forta  = train_node2vec(edges_forta, \"forta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d765b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Merge Per-Client Embeddings into Federated Matrix\n",
    "# ================================================================\n",
    "# Outer-join on Address\n",
    "merged = embed_kaggle.merge(embed_farr, on=\"Address\", how=\"outer\")\n",
    "merged = merged.merge(embed_forta, on=\"Address\", how=\"outer\")\n",
    "\n",
    "# Fill missing vectors with zeros\n",
    "embed_cols = [c for c in merged.columns if \"_emb_\" in c]\n",
    "merged[embed_cols] = merged[embed_cols].fillna(0)\n",
    "\n",
    "# Save federated embeddings\n",
    "print(\"Final merged embedding shape:\", merged.shape)\n",
    "merged.to_csv(\"federated_node2vec_embeddings.csv\", index=False)\n",
    "print(\"Saved federated_node2vec_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa48854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Add Federated Embeddings to Master Transactional Dataset\n",
    "# ================================================================\n",
    "import pandas as pd\n",
    "\n",
    "# Load base master + federated embeddings\n",
    "master = pd.read_csv(\"master_dataset_node2vec_base.csv\")\n",
    "fed    = pd.read_csv(\"federated_node2vec_embeddings.csv\")\n",
    "fed[\"Address\"] = fed[\"Address\"].str.lower()\n",
    "\n",
    "# Merge on Address\n",
    "master = master.merge(fed, on=\"Address\", how=\"left\")\n",
    "\n",
    "# Fill missing embedding values\n",
    "embed_cols = [c for c in master.columns if \"_emb_\" in c]\n",
    "master[embed_cols] = master[embed_cols].fillna(0)\n",
    "\n",
    "# Save updated master\n",
    "print(\"Merged federated embeddings.\")\n",
    "print(\"New master shape:\", master.shape)\n",
    "master.to_csv(\"master_dataset_federated_node2vec.csv\", index=False)\n",
    "print(\"Saved master_dataset_federated_node2vec.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d7210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Add Federated Embeddings to Master Transactional Dataset\n",
    "# ================================================================\n",
    "import pandas as pd\n",
    "\n",
    "# Load base master + federated embeddings\n",
    "master = pd.read_csv(\"master_dataset_node2vec_base.csv\")\n",
    "fed    = pd.read_csv(\"federated_node2vec_embeddings.csv\")\n",
    "fed[\"Address\"] = fed[\"Address\"].str.lower()\n",
    "\n",
    "# Merge on Address\n",
    "master = master.merge(fed, on=\"Address\", how=\"left\")\n",
    "\n",
    "# Fill missing embedding values\n",
    "embed_cols = [c for c in master.columns if \"_emb_\" in c]\n",
    "master[embed_cols] = master[embed_cols].fillna(0)\n",
    "\n",
    "# Save updated master\n",
    "print(\"Merged federated embeddings.\")\n",
    "print(\"New master shape:\", master.shape)\n",
    "master.to_csv(\"master_dataset_federated_node2vec.csv\", index=False)\n",
    "print(\"Saved master_dataset_federated_node2vec.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e618c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Preprocess Master Dataset (Scaling + One-Hot Encoding)\n",
    "# ================================================================\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Split numeric/categorical\n",
    "X_raw = df.drop(columns=[\"FLAG\",\"Address\"])\n",
    "cat_cols = X_raw.select_dtypes(\"object\").columns.tolist()\n",
    "num_cols = X_raw.select_dtypes(\"number\").columns.tolist()\n",
    "\n",
    "# Fill NaNs\n",
    "X_raw[num_cols] = X_raw[num_cols].fillna(0)\n",
    "\n",
    "# Define transformer\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", MinMaxScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_cols)\n",
    "])\n",
    "pre.fit(X_raw)\n",
    "\n",
    "# Transform helper\n",
    "def transform(X):\n",
    "    Xt = pre.transform(X)\n",
    "    if hasattr(Xt, \"toarray\"):\n",
    "        Xt = Xt.toarray()\n",
    "    return np.nan_to_num(Xt)\n",
    "\n",
    "# Apply to train/test\n",
    "Xt_train = transform(train_df.drop(columns=[\"FLAG\",\"Address\"]))\n",
    "Xt_test  = transform(test_df.drop(columns=[\"FLAG\",\"Address\"]))\n",
    "y_train, y_test = train_df[\"FLAG\"].values, test_df[\"FLAG\"].values\n",
    "\n",
    "print(\"Preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Balance Training Set with SMOTE\n",
    "# ================================================================\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "Xt_train, y_train = SMOTE(random_state=42).fit_resample(Xt_train, y_train)\n",
    "print(\"SMOTE balancing done. Train shape:\", Xt_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# EXPERIMENT: Federated Node2Vec Embeddings + Transactional Features (RF, XGB, MLP)\n",
    "# ================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load your federated feature dataset\n",
    "train_df = pd.read_csv(\"train_node2vec.csv\")  # If you split with federated features, use the federated train/test\n",
    "test_df  = pd.read_csv(\"test_node2vec.csv\")\n",
    "\n",
    "# Or, if you have separate splits, use:\n",
    "# train_df = pd.read_csv(\"train_federated.csv\")\n",
    "# test_df = pd.read_csv(\"test_federated.csv\")\n",
    "\n",
    "drop_cols = [\"FLAG\", \"Address\"]\n",
    "X_train_raw = train_df.drop(columns=drop_cols)\n",
    "y_train     = train_df[\"FLAG\"].values\n",
    "\n",
    "X_test_raw  = test_df.drop(columns=drop_cols)\n",
    "y_test      = test_df[\"FLAG\"].values\n",
    "\n",
    "# Fill NaNs just in case\n",
    "num_cols = X_train_raw.select_dtypes(\"number\").columns.tolist()\n",
    "cat_cols = X_train_raw.select_dtypes(\"object\").columns.tolist()\n",
    "X_train_raw[num_cols] = X_train_raw[num_cols].fillna(0)\n",
    "X_test_raw[num_cols]  = X_test_raw[num_cols].fillna(0)\n",
    "\n",
    "# Preprocess\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", MinMaxScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_cols)\n",
    "])\n",
    "preprocess.fit(X_train_raw)\n",
    "\n",
    "def transform(X):\n",
    "    Xt = preprocess.transform(X)\n",
    "    if hasattr(Xt, \"toarray\"):\n",
    "        Xt = Xt.toarray()\n",
    "    return np.nan_to_num(Xt)\n",
    "\n",
    "Xt_train = transform(X_train_raw)\n",
    "Xt_test  = transform(X_test_raw)\n",
    "\n",
    "# SMOTE balancing on train only\n",
    "Xt_train, y_train = SMOTE(random_state=42).fit_resample(Xt_train, y_train)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=400, class_weight=\"balanced\", n_jobs=-1, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=600, max_depth=6, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8,\n",
    "                             scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
    "                             eval_metric=\"auc\", n_jobs=-1, random_state=42),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(256,128), max_iter=40, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n=== {name} (Federated Node2Vec + Transactional) ===\")\n",
    "    clf.fit(Xt_train, y_train)\n",
    "\n",
    "    prob = clf.predict_proba(Xt_test)[:,1]\n",
    "    preds = (prob >= 0.5).astype(int)\n",
    "\n",
    "    roc = roc_auc_score(y_test, prob)\n",
    "    pr  = average_precision_score(y_test, prob)\n",
    "\n",
    "    print(f\"ROC-AUC: {roc:.3f} | PR-AUC: {pr:.3f}\")\n",
    "    print(classification_report(y_test, preds))\n",
    "\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    results.append(dict(model=name, roc=roc, pr=pr,\n",
    "                        TP=cm[1,1], FP=cm[0,1],\n",
    "                        FN=cm[1,0], TN=cm[0,0]))\n",
    "\n",
    "    joblib.dump(clf, f\"clf_federated_{name.lower()}.joblib\")\n",
    "\n",
    "pd.DataFrame(results).to_csv(\"federated_metrics.csv\", index=False)\n",
    "print(\"\\n Results saved to federated_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73dc780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load all metrics CSVs (ensure these files were generated in previous steps)\n",
    "df_txn        = pd.read_csv(\"baseline_metrics.csv\")              # Transactional only\n",
    "df_n2v        = pd.read_csv(\"embeddings_only_metrics.csv\")       # Node2Vec only\n",
    "df_hybrid     = pd.read_csv(\"node2vec_metrics.csv\")              # Hybrid\n",
    "df_federated  = pd.read_csv(\"federated_metrics.csv\")             # Federated\n",
    "\n",
    "# Tag model type for each\n",
    "df_txn[\"type\"] = \"Transactional\"\n",
    "df_n2v[\"type\"] = \"Node2Vec\"\n",
    "df_hybrid[\"type\"] = \"Hybrid\"\n",
    "df_federated[\"type\"] = \"Federated\"\n",
    "\n",
    "# Concatenate into single DataFrame\n",
    "combined = pd.concat([df_txn, df_n2v, df_hybrid, df_federated], ignore_index=True)\n",
    "\n",
    "combined[\"model\"] = combined[\"model\"].replace({\n",
    "    \"RandomForest\": \"RF\",\n",
    "    \"XGBoost\": \"XGB\"\n",
    "})\n",
    "\n",
    "# Pivot for bar chart: separate ROC and PR for grouped bars\n",
    "roc_data = combined.pivot(index=\"model\", columns=\"type\", values=\"roc\")\n",
    "pr_data  = combined.pivot(index=\"model\", columns=\"type\", values=\"pr\")\n",
    "\n",
    "\n",
    "# Plot: Clustered bars for ROC + PR-AUC per model\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "bar_width = 0.2\n",
    "models = roc_data.index.tolist()\n",
    "types  = [\"Transactional\", \"Node2Vec\", \"Hybrid\", \"Federated\"]\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\"]\n",
    "\n",
    "# ROC-AUC chart\n",
    "for i, t in enumerate(types):\n",
    "    axs[0].bar(np.arange(len(models)) + i*bar_width,\n",
    "               roc_data[t].values,\n",
    "               width=bar_width, label=t, color=colors[i])\n",
    "axs[0].set_xticks(np.arange(len(models)) + bar_width*1.5)\n",
    "axs[0].set_xticklabels(models)\n",
    "axs[0].set_ylim(0.0, 1.05)\n",
    "axs[0].set_ylabel(\"ROC-AUC\")\n",
    "axs[0].set_title(\"ROC-AUC Comparison by Model Type\")\n",
    "axs[0].legend()\n",
    "\n",
    "# PR-AUC chart\n",
    "for i, t in enumerate(types):\n",
    "    axs[1].bar(np.arange(len(models)) + i*bar_width,\n",
    "               pr_data[t].values,\n",
    "               width=bar_width, label=t, color=colors[i])\n",
    "axs[1].set_xticks(np.arange(len(models)) + bar_width*1.5)\n",
    "axs[1].set_xticklabels(models)\n",
    "axs[1].set_ylim(0.0, 1.05)\n",
    "axs[1].set_ylabel(\"PR-AUC\")\n",
    "axs[1].set_title(\"PR-AUC Comparison by Model Type\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.suptitle(\"Model Performance: Federated Node2Vec vs Other Representations\", fontsize=15)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# STEP 3: Stratified K-Fold Cross-Validation (RF, XGB only)\n",
    "# ================================================================\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load federated Node2Vec dataset\n",
    "df = pd.read_csv(\"master_dataset_federated_node2vec.csv\")\n",
    "\n",
    "drop_cols = [\"FLAG\", \"Address\"]\n",
    "X_raw = df.drop(columns=drop_cols)\n",
    "y = df[\"FLAG\"].values\n",
    "\n",
    "cat_cols = X_raw.select_dtypes(\"object\").columns.tolist()\n",
    "num_cols = X_raw.select_dtypes(\"number\").columns.tolist()\n",
    "X_raw[num_cols] = X_raw[num_cols].fillna(0)\n",
    "\n",
    "# K-Fold\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# To store results per model\n",
    "metrics = {\n",
    "    \"RandomForest\": {\"roc\": [], \"pr\": []},\n",
    "    \"XGBoost\": {\"roc\": [], \"pr\": []}\n",
    "}\n",
    "\n",
    "fold = 1\n",
    "for train_idx, test_idx in kf.split(X_raw, y):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    X_train, y_train = X_raw.iloc[train_idx], y[train_idx]\n",
    "    X_test,  y_test  = X_raw.iloc[test_idx],  y[test_idx]\n",
    "\n",
    "    # Preprocess per fold\n",
    "    pre = ColumnTransformer([\n",
    "        (\"num\", MinMaxScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_cols)\n",
    "    ])\n",
    "    pre.fit(X_train)\n",
    "\n",
    "    def transform(X):\n",
    "        Xt = pre.transform(X)\n",
    "        if hasattr(Xt, \"toarray\"):\n",
    "            Xt = Xt.toarray()\n",
    "        return np.nan_to_num(Xt)\n",
    "\n",
    "    Xt_train = transform(X_train)\n",
    "    Xt_test  = transform(X_test)\n",
    "\n",
    "    # SMOTE\n",
    "    Xt_train, y_train = SMOTE(random_state=42).fit_resample(Xt_train, y_train)\n",
    "\n",
    "    # Define models\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=400, class_weight=\"balanced\", n_jobs=-1, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(n_estimators=600, max_depth=6, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8,\n",
    "                                 scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
    "                                 eval_metric=\"auc\", n_jobs=-1, random_state=42)\n",
    "    }\n",
    "\n",
    "    for name, clf in models.items():\n",
    "        clf.fit(Xt_train, y_train)\n",
    "        prob = clf.predict_proba(Xt_test)[:,1]\n",
    "        roc  = roc_auc_score(y_test, prob)\n",
    "        pr   = average_precision_score(y_test, prob)\n",
    "        metrics[name][\"roc\"].append(roc)\n",
    "        metrics[name][\"pr\"].append(pr)\n",
    "        print(f\"{name}: ROC-AUC: {roc:.3f} | PR-AUC: {pr:.3f}\")\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# Show summary for each model\n",
    "print(\"\\n=== CV Summary ===\")\n",
    "for name in metrics:\n",
    "    print(f\"{name}: Mean ROC-AUC: {np.mean(metrics[name]['roc']):.3f} | Mean PR-AUC: {np.mean(metrics[name]['pr']):.3f}\")\n",
    "\n",
    "# Save to file\n",
    "cv_results = pd.DataFrame({\n",
    "    \"Model\": sum([[name]*5 for name in metrics], []),\n",
    "    \"Fold\": list(range(1,6))*2,\n",
    "    \"ROC-AUC\": metrics[\"RandomForest\"][\"roc\"] + metrics[\"XGBoost\"][\"roc\"],\n",
    "    \"PR-AUC\": metrics[\"RandomForest\"][\"pr\"] + metrics[\"XGBoost\"][\"pr\"]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c27752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# STEP 3+4: Stratified K-Fold Cross-Validation (Selected Folds) + Plot\n",
    "# ================================================================\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load federated Node2Vec dataset\n",
    "df = pd.read_csv(\"master_dataset_federated_node2vec.csv\")\n",
    "drop_cols = [\"FLAG\", \"Address\"]\n",
    "X_raw = df.drop(columns=drop_cols)\n",
    "y = df[\"FLAG\"].values\n",
    "\n",
    "cat_cols = X_raw.select_dtypes(\"object\").columns.tolist()\n",
    "num_cols = X_raw.select_dtypes(\"number\").columns.tolist()\n",
    "X_raw[num_cols] = X_raw[num_cols].fillna(0)\n",
    "\n",
    "# Define specific folds to include\n",
    "target_folds = [1, 5, 10, 12]\n",
    "kf = StratifiedKFold(n_splits=15, shuffle=True, random_state=42)\n",
    "\n",
    "metrics = {\n",
    "    \"Model\": [],\n",
    "    \"Fold\": [],\n",
    "    \"ROC-AUC\": [],\n",
    "    \"PR-AUC\": []\n",
    "}\n",
    "\n",
    "fold = 1\n",
    "for train_idx, test_idx in kf.split(X_raw, y):\n",
    "    if fold not in target_folds:\n",
    "        fold += 1\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    X_train, y_train = X_raw.iloc[train_idx], y[train_idx]\n",
    "    X_test,  y_test  = X_raw.iloc[test_idx],  y[test_idx]\n",
    "\n",
    "    pre = ColumnTransformer([\n",
    "        (\"num\", MinMaxScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_cols)\n",
    "    ])\n",
    "    pre.fit(X_train)\n",
    "\n",
    "    def transform(X):\n",
    "        Xt = pre.transform(X)\n",
    "        if hasattr(Xt, \"toarray\"):\n",
    "            Xt = Xt.toarray()\n",
    "        return np.nan_to_num(Xt)\n",
    "\n",
    "    Xt_train = transform(X_train)\n",
    "    Xt_test  = transform(X_test)\n",
    "    Xt_train, y_train = SMOTE(random_state=42).fit_resample(Xt_train, y_train)\n",
    "\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=400, class_weight=\"balanced\", n_jobs=-1, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            n_estimators=600, max_depth=6, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
    "            eval_metric=\"auc\", n_jobs=-1, random_state=42\n",
    "        )\n",
    "    }\n",
    "\n",
    "    for name, clf in models.items():\n",
    "        clf.fit(Xt_train, y_train)\n",
    "        prob = clf.predict_proba(Xt_test)[:, 1]\n",
    "        roc  = roc_auc_score(y_test, prob)\n",
    "        pr   = average_precision_score(y_test, prob)\n",
    "        print(f\"{name}: ROC-AUC: {roc:.3f} | PR-AUC: {pr:.3f}\")\n",
    "        metrics[\"Model\"].append(name)\n",
    "        metrics[\"Fold\"].append(fold)\n",
    "        metrics[\"ROC-AUC\"].append(roc)\n",
    "        metrics[\"PR-AUC\"].append(pr)\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "cv_df = pd.DataFrame(metrics)\n",
    "cv_df.to_csv(\"cv_results_selected_folds.csv\", index=False)\n",
    "print(\"Saved: cv_results_selected_folds.csv\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Plot the results\n",
    "# --------------------------------------------------\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# ROC-AUC Boxplot\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(data=cv_df, x=\"Model\", y=\"ROC-AUC\", palette=\"Set2\")\n",
    "sns.stripplot(data=cv_df, x=\"Model\", y=\"ROC-AUC\", color='black', size=6, jitter=True)\n",
    "plt.title(\"Stratified CV (Folds 1, 5, 10, 12) – ROC-AUC\")\n",
    "plt.grid(True)\n",
    "\n",
    "# PR-AUC Boxplot\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=cv_df, x=\"Model\", y=\"PR-AUC\", palette=\"Set2\")\n",
    "sns.stripplot(data=cv_df, x=\"Model\", y=\"PR-AUC\", color='black', size=6, jitter=True)\n",
    "plt.title(\"Stratified CV (Folds 1, 5, 10, 12) – PR-AUC\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cv_performance_summary.png\", dpi=300)\n",
    "print(\"Saved: cv_performance_summary.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6053b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Robustness Evaluation (Federated Node2Vec + Transactional Features)\n",
    "# ================================================================\n",
    "import numpy as np, pandas as pd, joblib, warnings\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    matthews_corrcoef, cohen_kappa_score, confusion_matrix\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(\"train_node2vec.csv\")\n",
    "test_df  = pd.read_csv(\"test_node2vec.csv\")\n",
    "\n",
    "# Prepare columns\n",
    "drop_cols = [\"FLAG\", \"Address\"]\n",
    "X_raw = pd.concat([train_df, test_df]).drop(columns=drop_cols)\n",
    "cat_cols = X_raw.select_dtypes(\"object\").columns.tolist()\n",
    "num_cols = X_raw.select_dtypes(\"number\").columns.tolist()\n",
    "\n",
    "# Fill NaNs\n",
    "train_df[num_cols] = train_df[num_cols].fillna(0)\n",
    "test_df[num_cols]  = test_df[num_cols].fillna(0)\n",
    "\n",
    "# Define and fit preprocessor\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", MinMaxScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_cols)\n",
    "])\n",
    "preprocess.fit(train_df.drop(columns=drop_cols))\n",
    "\n",
    "# Transform data\n",
    "X_train_full = preprocess.transform(train_df.drop(columns=drop_cols))\n",
    "y_train_full = train_df[\"FLAG\"].values\n",
    "X_test       = preprocess.transform(test_df.drop(columns=drop_cols))\n",
    "y_test       = test_df[\"FLAG\"].values\n",
    "\n",
    "# Scoring helper\n",
    "def score_model(model_name, clf, xt=X_test, yt=y_test):\n",
    "    prob  = clf.predict_proba(xt)[:, 1]\n",
    "    preds = (prob >= 0.5).astype(int)\n",
    "    return dict(\n",
    "        model   = model_name,\n",
    "        roc_auc = roc_auc_score(yt, prob),\n",
    "        pr_auc  = average_precision_score(yt, prob),\n",
    "        mcc     = matthews_corrcoef(yt, preds),\n",
    "        kappa   = cohen_kappa_score(yt, preds)\n",
    "    )\n",
    "\n",
    "# Model builders\n",
    "def get_xgb(y_train):\n",
    "    return XGBClassifier(\n",
    "        n_estimators=600, max_depth=6, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
    "        eval_metric='auc', n_jobs=-1, random_state=42\n",
    "    )\n",
    "\n",
    "def get_rf():\n",
    "    return RandomForestClassifier(n_estimators=400, class_weight='balanced', n_jobs=-1, random_state=42)\n",
    "\n",
    "# Run experiments\n",
    "results = []\n",
    "\n",
    "# 1. Baseline\n",
    "print(\"\\n--- Training Baseline models (XGB & RF) ---\")\n",
    "X_train_bal, y_train_bal = SMOTE(random_state=42).fit_resample(X_train_full, y_train_full)\n",
    "for name, clf_factory in [(\"Baseline_XGB\", lambda: get_xgb(y_train_bal)),\n",
    "                          (\"Baseline_RF\", get_rf)]:\n",
    "    print(f\"  Training {name} ...\")\n",
    "    clf = clf_factory()\n",
    "    clf.fit(X_train_bal, y_train_bal)\n",
    "    results.append(score_model(name, clf))\n",
    "\n",
    "# 2. Label Noise\n",
    "for noise_pct in [0.05, 0.10, 0.20, 0.35, 0.40, 0.45, 0.50]:\n",
    "    print(f\"\\n--- Label Noise: Flipping {int(noise_pct*100)}% of labels ---\")\n",
    "    y_noisy = y_train_full.copy()\n",
    "    flip_idx = np.random.choice(len(y_noisy), int(len(y_noisy) * noise_pct), replace=False)\n",
    "    y_noisy[flip_idx] = 1 - y_noisy[flip_idx]\n",
    "    X_bal, y_bal = SMOTE(random_state=42).fit_resample(X_train_full, y_noisy)\n",
    "\n",
    "    for name, clf_factory in [(f\"LabelNoise{int(noise_pct*100)}%_XGB\", lambda: get_xgb(y_bal)),\n",
    "                              (f\"LabelNoise{int(noise_pct*100)}%_RF\", get_rf)]:\n",
    "        print(f\"  Training {name} ...\")\n",
    "        clf = clf_factory()\n",
    "        clf.fit(X_bal, y_bal)\n",
    "        results.append(score_model(name, clf))\n",
    "\n",
    "# Save and display\n",
    "robust_df = pd.DataFrame(results)\n",
    "robust_df.to_csv(\"robustness_metrics.csv\", index=False)\n",
    "print(\"\\n Robustness evaluation complete. Results saved to robustness_metrics.csv\")\n",
    "robust_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5dd738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "#  robustness test\n",
    "#  Federated Node2Vec + transactional features\n",
    "#  Models: Random-Forest  &  XGBoost\n",
    "# ================================================================\n",
    "import numpy as np, pandas as pd, time, warnings\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score,\n",
    "                             matthews_corrcoef, cohen_kappa_score)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# ---------- CONFIG ------------------------------------------------\n",
    "CSV_TRAIN  = \"train_node2vec.csv\"\n",
    "CSV_TEST   = \"test_node2vec.csv\"\n",
    "DROP_PCTS  = [0.50, 0.60, 0.70, 0.80, 0.85, 0.90, 0.95, 0.99]          \n",
    "RNG        = np.random.default_rng(42)\n",
    "SMOTE_KW   = dict(random_state=42)\n",
    "\n",
    "# ---------- LOAD --------------------------------------------------\n",
    "print(\" Loading data …\")\n",
    "train_df = pd.read_csv(CSV_TRAIN)\n",
    "test_df  = pd.read_csv(CSV_TEST)\n",
    "\n",
    "y_train = train_df[\"FLAG\"].values\n",
    "y_test  = test_df[\"FLAG\"].values\n",
    "X_train_raw = train_df.drop(columns=[\"FLAG\", \"Address\"])\n",
    "X_test_raw  = test_df.drop(columns=[\"FLAG\", \"Address\"])\n",
    "\n",
    "# ---------- PRE-PROCESS ------------------------------------------\n",
    "print(\" Building pre-processor …\")\n",
    "num_cols = X_train_raw.select_dtypes(\"number\").columns.tolist()\n",
    "cat_cols = X_train_raw.select_dtypes(\"object\").columns.tolist()\n",
    "\n",
    "X_train_raw[num_cols] = X_train_raw[num_cols].fillna(0)\n",
    "X_test_raw[num_cols]  = X_test_raw[num_cols].fillna(0)\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", MinMaxScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_cols)\n",
    "])\n",
    "pre.fit(X_train_raw)\n",
    "\n",
    "def transform(df):\n",
    "    X = pre.transform(df)\n",
    "    return np.nan_to_num(X.toarray() if hasattr(X, \"toarray\") else X)\n",
    "\n",
    "X_train_full = transform(X_train_raw)\n",
    "X_test_full  = transform(X_test_raw)\n",
    "n_features   = X_train_full.shape[1]\n",
    "print(f\" Encoded feature space: {n_features:,d} columns\")\n",
    "\n",
    "# ---------- MODEL BUILDERS ---------------------------------------\n",
    "def build_rf():\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators = 400,\n",
    "        class_weight = \"balanced\",\n",
    "        n_jobs       = -1,\n",
    "        random_state = 42,\n",
    "    )\n",
    "\n",
    "def build_xgb(y):\n",
    "    return XGBClassifier(\n",
    "        n_estimators     = 600,\n",
    "        max_depth        = 6,\n",
    "        learning_rate    = 0.05,\n",
    "        subsample        = 0.8,\n",
    "        colsample_bytree = 0.8,\n",
    "        scale_pos_weight = (y == 0).sum() / (y == 1).sum(),\n",
    "        eval_metric      = \"auc\",\n",
    "        n_jobs           = -1,\n",
    "        random_state     = 42,\n",
    "        verbosity        = 0,\n",
    "    )\n",
    "\n",
    "# ---------- METRIC HELPER ----------------------------------------\n",
    "def evaluate(tag, clf, Xte, yte):\n",
    "    proba = clf.predict_proba(Xte)[:, 1]\n",
    "    pred  = (proba >= 0.5).astype(int)\n",
    "    return dict(\n",
    "        tag     = tag,\n",
    "        roc_auc = roc_auc_score(yte, proba),\n",
    "        pr_auc  = average_precision_score(yte, proba),\n",
    "        mcc     = matthews_corrcoef(yte, pred),\n",
    "        kappa   = cohen_kappa_score(yte, pred),\n",
    "    )\n",
    "\n",
    "# ---------- RUN EXPERIMENT ---------------------------------------\n",
    "records = []\n",
    "\n",
    "## A. Baseline -----------------------------------------------------\n",
    "print(\"\\n Training baselines (RF & XGB) …\")\n",
    "X_bal, y_bal = SMOTE(**SMOTE_KW).fit_resample(X_train_full, y_train)\n",
    "\n",
    "rf_base  = build_rf();  rf_base.fit(X_bal, y_bal)\n",
    "xgb_base = build_xgb(y_bal); xgb_base.fit(X_bal, y_bal)\n",
    "\n",
    "records.append(evaluate(\"Baseline_RF\",  rf_base,  X_test_full, y_test))\n",
    "records.append(evaluate(\"Baseline_XGB\", xgb_base, X_test_full, y_test))\n",
    "\n",
    "## B. Nested feature-drop loop ------------------------------------\n",
    "print(\"\\n Creating a single random column order for nested masks …\")\n",
    "perm_idx = RNG.permutation(n_features)     # fixed ordering\n",
    "\n",
    "for pct in DROP_PCTS:                      # 0.50, 0.80, 0.95\n",
    "    keep_frac = 1.0 - pct                  # 0.50, 0.20, 0.05\n",
    "    k = int(n_features * keep_frac)\n",
    "    keep_idx = perm_idx[:k]                # nested subset\n",
    "\n",
    "    print(f\"\\n Feature-drop {int(pct*100)} %  \"\n",
    "          f\"(keeping {k}/{n_features} columns ≈ {keep_frac:0.0%})\")\n",
    "\n",
    "    Xtr = X_train_full[:, keep_idx]\n",
    "    Xte = X_test_full[:,  keep_idx]\n",
    "    X_bal, y_bal = SMOTE(**SMOTE_KW).fit_resample(Xtr, y_train)\n",
    "\n",
    "    rf  = build_rf();         rf.fit(X_bal, y_bal)\n",
    "    xgb = build_xgb(y_bal);   xgb.fit(X_bal, y_bal)\n",
    "\n",
    "    records.append(evaluate(f\"FeatDrop{int(pct*100)}%_RF\",  rf,  Xte, y_test))\n",
    "    records.append(evaluate(f\"FeatDrop{int(pct*100)}%_XGB\", xgb, Xte, y_test))\n",
    "\n",
    "# ---------- RESULTS ----------------------------------------------\n",
    "raw_df = pd.DataFrame(records)\n",
    "\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:0.5f}\")\n",
    "print(\"\\n================  Robustness Results  ================\")\n",
    "print(raw_df.loc[:, [\"tag\", \"roc_auc\", \"pr_auc\", \"mcc\", \"kappa\"]]\n",
    "          .to_string(index=False))\n",
    "print(\"======================================================\")\n",
    "\n",
    "raw_df.to_csv(\"fed_feature_drop_quick.csv\", index=False)\n",
    "print(f\"\\n Results saved to fed_feature_drop_quick.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Robustness Plots: Label Noise & Feature Dropout\n",
    "# ================================================================\n",
    "import pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "# Load results\n",
    "label_noise_df  = pd.read_csv(\"robustness_metrics.csv\")\n",
    "feature_drop_df = pd.read_csv(\"fed_feature_drop_quick.csv\")\n",
    "\n",
    "# Extract noise/drop %\n",
    "label_noise_df[\"noise_pct\"] = label_noise_df[\"model\"].str.extract(r\"LabelNoise(\\d+)%\")[0].astype(float)\n",
    "label_noise_df = label_noise_df.dropna(subset=[\"noise_pct\"])\n",
    "feature_drop_df[\"drop_pct\"] = feature_drop_df[\"tag\"].str.extract(r\"FeatDrop(\\d+)%\")[0].astype(float)\n",
    "feature_drop_df = feature_drop_df.dropna(subset=[\"drop_pct\"])\n",
    "\n",
    "# Setup subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Label Noise curves\n",
    "for model in [\"XGB\", \"RF\"]:\n",
    "    subset = label_noise_df[label_noise_df[\"model\"].str.contains(model)]\n",
    "    ax[0].plot(subset[\"noise_pct\"], subset[\"roc_auc\"], marker='o', label=f\"{model} ROC-AUC\")\n",
    "    ax[0].plot(subset[\"noise_pct\"], subset[\"pr_auc\"], marker='s', label=f\"{model} PR-AUC\")\n",
    "ax[0].set_title(\"Label Noise vs ROC/PR-AUC\")\n",
    "ax[0].set_xlabel(\"Label Noise (%)\")\n",
    "ax[0].set_ylabel(\"Score\")\n",
    "ax[0].set_ylim(0, 1.05)\n",
    "ax[0].legend()\n",
    "ax[0].grid(True)\n",
    "\n",
    "# Feature Drop curves\n",
    "for model in [\"XGB\", \"RF\"]:\n",
    "    subset = feature_drop_df[feature_drop_df[\"tag\"].str.contains(model)]\n",
    "    ax[1].plot(subset[\"drop_pct\"], subset[\"roc_auc\"], marker='o', label=f\"{model} ROC-AUC\")\n",
    "    ax[1].plot(subset[\"drop_pct\"], subset[\"pr_auc\"], marker='s', label=f\"{model} PR-AUC\")\n",
    "ax[1].set_title(\"Feature Dropout vs ROC/PR-AUC\")\n",
    "ax[1].set_xlabel(\"Feature Drop (%)\")\n",
    "ax[1].set_ylabel(\"Score\")\n",
    "ax[1].set_ylim(0, 1.05)\n",
    "ax[1].legend()\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946a49d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# SHAP Explainability – Random Forest on Node2Vec + Tx Features\n",
    "# ================================================================\n",
    "import pandas as pd, numpy as np, shap, matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. Load train/test\n",
    "train_df, test_df = pd.read_csv(\"train_node2vec.csv\"), pd.read_csv(\"test_node2vec.csv\")\n",
    "drop_cols = [\"FLAG\",\"Address\"]\n",
    "X_train_raw, y_train = train_df.drop(columns=drop_cols), train_df[\"FLAG\"].astype(int).values\n",
    "X_test_raw,  y_test  = test_df.drop(columns=drop_cols),  test_df[\"FLAG\"].astype(int).values\n",
    "\n",
    "# 2. Preprocess (scale numeric, one-hot categorical)\n",
    "num_cols = X_train_raw.select_dtypes(\"number\").columns.tolist()\n",
    "cat_cols = X_train_raw.select_dtypes(\"object\").columns.tolist()\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", MinMaxScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "]).fit(X_train_raw)\n",
    "\n",
    "def transform(X):\n",
    "    Xt = pre.transform(X)\n",
    "    return Xt.toarray() if hasattr(Xt, \"toarray\") else np.nan_to_num(Xt)\n",
    "\n",
    "Xt_train, Xt_test = transform(X_train_raw), transform(X_test_raw)\n",
    "feature_names = list(num_cols) + (list(pre.named_transformers_[\"cat\"].get_feature_names_out(cat_cols)) if cat_cols else [])\n",
    "print(\"Xt_train:\", Xt_train.shape, \"| Xt_test:\", Xt_test.shape)\n",
    "\n",
    "# 3. Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=400, class_weight=\"balanced\", n_jobs=-1, random_state=42)\n",
    "rf.fit(Xt_train, y_train)\n",
    "\n",
    "# 4. Global importances\n",
    "fi = pd.Series(rf.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "print(\"\\nTop 20 Features:\\n\", fi.head(20))\n",
    "\n",
    "# 5. SHAP values\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(Xt_test)\n",
    "\n",
    "# Handle SHAP output formats\n",
    "if isinstance(shap_values, list):\n",
    "    sv = [arr for arr in shap_values if arr.shape[1] == Xt_test.shape[1]][0]\n",
    "elif len(shap_values.shape) == 3 and shap_values.shape[2] == 2:\n",
    "    sv = shap_values[..., 1]\n",
    "else:\n",
    "    sv = shap_values\n",
    "print(\"SHAP values shape:\", sv.shape)\n",
    "\n",
    "# 6. SHAP summary plot (global)\n",
    "shap.summary_plot(sv, Xt_test, feature_names=feature_names, max_display=20, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary_plot.png\")\n",
    "plt.close()\n",
    "print(\"Saved shap_summary_plot.png\")\n",
    "\n",
    "# 7. Predictions + error analysis\n",
    "prob = rf.predict_proba(Xt_test)[:,1]\n",
    "preds = (prob >= 0.5).astype(int)\n",
    "mis_idx = np.where(preds != y_test)[0]\n",
    "tp_idx  = np.where((preds == 1) & (y_test == 1))[0]\n",
    "\n",
    "# 8. SHAP local case studies\n",
    "if len(mis_idx) > 0:\n",
    "    idx = mis_idx[0]\n",
    "    shap.plots._waterfall.waterfall_legacy(explainer.expected_value[1], sv[idx], feature_names=feature_names)\n",
    "    plt.title(\"SHAP Waterfall – Misclassified Example\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"shap_waterfall_misclassified.png\")\n",
    "    plt.close()\n",
    "\n",
    "if len(tp_idx) > 0:\n",
    "    idx = tp_idx[0]\n",
    "    shap.plots._waterfall.waterfall_legacy(explainer.expected_value[1], sv[idx], feature_names=feature_names)\n",
    "    plt.title(\"SHAP Waterfall – True Positive Example\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"shap_waterfall_truepositive.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"SHAP summary + case study plots saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# SHAP Explainability – XGBoost on Node2Vec + Tx Features\n",
    "# ================================================================\n",
    "import pandas as pd, numpy as np, shap, matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 1. Load train/test\n",
    "train_df, test_df = pd.read_csv(\"train_node2vec.csv\"), pd.read_csv(\"test_node2vec.csv\")\n",
    "drop_cols = [\"FLAG\",\"Address\"]\n",
    "X_train_raw, y_train = train_df.drop(columns=drop_cols), train_df[\"FLAG\"].astype(int).values\n",
    "X_test_raw,  y_test  = test_df.drop(columns=drop_cols),  test_df[\"FLAG\"].astype(int).values\n",
    "\n",
    "# 2. Preprocess\n",
    "num_cols = X_train_raw.select_dtypes(\"number\").columns.tolist()\n",
    "cat_cols = X_train_raw.select_dtypes(\"object\").columns.tolist()\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", MinMaxScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "]).fit(X_train_raw)\n",
    "\n",
    "def transform(X):\n",
    "    Xt = pre.transform(X)\n",
    "    return Xt.toarray() if hasattr(Xt,\"toarray\") else np.nan_to_num(Xt)\n",
    "\n",
    "Xt_train, Xt_test = transform(X_train_raw), transform(X_test_raw)\n",
    "feature_names = list(num_cols) + (list(pre.named_transformers_[\"cat\"].get_feature_names_out(cat_cols)) if cat_cols else [])\n",
    "print(\"Xt_train:\", Xt_train.shape, \"| Xt_test:\", Xt_test.shape)\n",
    "\n",
    "# 3. Train XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=600, max_depth=6, learning_rate=0.05,\n",
    "    subsample=0.8, colsample_bytree=0.8,\n",
    "    scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
    "    eval_metric=\"auc\", n_jobs=-1, random_state=42, use_label_encoder=False\n",
    ")\n",
    "xgb.fit(Xt_train, y_train)\n",
    "\n",
    "# 4. Global importances\n",
    "fi = pd.Series(xgb.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "print(\"\\nTop 20 Features:\\n\", fi.head(20))\n",
    "\n",
    "# 5. SHAP values\n",
    "explainer = shap.TreeExplainer(xgb)\n",
    "shap_values = explainer.shap_values(Xt_test)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    sv = [arr for arr in shap_values if arr.shape[1]==Xt_test.shape[1]][0]\n",
    "elif len(shap_values.shape)==3 and shap_values.shape[2]==2:\n",
    "    sv = shap_values[...,1]\n",
    "else:\n",
    "    sv = shap_values\n",
    "print(\"SHAP values shape:\", sv.shape)\n",
    "\n",
    "# 6. SHAP summary plot\n",
    "shap.summary_plot(sv, Xt_test, feature_names=feature_names, max_display=20, show=False)\n",
    "plt.tight_layout(); plt.savefig(\"shap_summary_plot_xgb.png\"); plt.close()\n",
    "print(\"Saved shap_summary_plot_xgb.png\")\n",
    "\n",
    "# 7. Predictions + error analysis\n",
    "prob, preds = xgb.predict_proba(Xt_test)[:,1], None\n",
    "preds = (prob >= 0.5).astype(int)\n",
    "mis_idx = np.where(preds != y_test)[0]\n",
    "tp_idx  = np.where((preds==1) & (y_test==1))[0]\n",
    "\n",
    "# 8. SHAP local case studies\n",
    "if len(mis_idx)>0:\n",
    "    idx = mis_idx[0]\n",
    "    shap.plots._waterfall.waterfall_legacy(explainer.expected_value, sv[idx], feature_names=feature_names)\n",
    "    plt.title(\"SHAP Waterfall – Misclassified (XGB)\")\n",
    "    plt.tight_layout(); plt.savefig(\"shap_waterfall_misclassified_xgb.png\"); plt.close()\n",
    "\n",
    "if len(tp_idx)>0:\n",
    "    idx = tp_idx[0]\n",
    "    shap.plots._waterfall.waterfall_legacy(explainer.expected_value, sv[idx], feature_names=feature_names)\n",
    "    plt.title(\"SHAP Waterfall – True Positive (XGB)\")\n",
    "    plt.tight_layout(); plt.savefig(\"shap_waterfall_truepositive_xgb.png\"); plt.close()\n",
    "\n",
    "print(\"SHAP summary + case study plots saved (XGBoost).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# SHAP Explainability – MLP on Node2Vec + Tx Features\n",
    "# ================================================================\n",
    "import pandas as pd, numpy as np, shap, matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 1. Load train/test\n",
    "train_df, test_df = pd.read_csv(\"train_node2vec.csv\"), pd.read_csv(\"test_node2vec.csv\")\n",
    "drop_cols = [\"FLAG\",\"Address\"]\n",
    "X_train_raw, y_train = train_df.drop(columns=drop_cols), train_df[\"FLAG\"].astype(int).values\n",
    "X_test_raw,  y_test  = test_df.drop(columns=drop_cols),  test_df[\"FLAG\"].astype(int).values\n",
    "\n",
    "# 2. Preprocess\n",
    "num_cols = X_train_raw.select_dtypes(\"number\").columns.tolist()\n",
    "cat_cols = X_train_raw.select_dtypes(\"object\").columns.tolist()\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", MinMaxScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "]).fit(X_train_raw)\n",
    "\n",
    "def transform(X):\n",
    "    Xt = pre.transform(X)\n",
    "    return Xt.toarray() if hasattr(Xt,\"toarray\") else np.nan_to_num(Xt)\n",
    "\n",
    "Xt_train, Xt_test = transform(X_train_raw), transform(X_test_raw)\n",
    "feature_names = list(num_cols) + (list(pre.named_transformers_[\"cat\"].get_feature_names_out(cat_cols)) if cat_cols else [])\n",
    "print(\"Xt_train:\", Xt_train.shape, \"| Xt_test:\", Xt_test.shape)\n",
    "\n",
    "# 3. Train MLP\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256,128), max_iter=40, random_state=42)\n",
    "mlp.fit(Xt_train, y_train)\n",
    "print(f\"MLP train acc: {mlp.score(Xt_train,y_train):.3f}, test acc: {mlp.score(Xt_test,y_test):.3f}\")\n",
    "\n",
    "# 4. SHAP (KernelExplainer with sampled background + test set)\n",
    "X_bg  = shap.sample(Xt_train, 100) if Xt_train.shape[0]>100 else Xt_train\n",
    "X_exp = shap.sample(Xt_test, 100)  if Xt_test.shape[0]>100  else Xt_test\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_bg)\n",
    "shap_values = explainer.shap_values(X_exp, nsamples=100)\n",
    "\n",
    "# Pick correct SHAP array\n",
    "if isinstance(shap_values, list):\n",
    "    sv = [arr for arr in shap_values if arr.shape[1]==X_exp.shape[1]][0]\n",
    "elif len(shap_values.shape)==3 and shap_values.shape[2]==2:\n",
    "    sv = shap_values[...,1]\n",
    "else:\n",
    "    sv = shap_values\n",
    "print(\"SHAP values shape:\", sv.shape)\n",
    "\n",
    "# 5. SHAP summary plot\n",
    "shap.summary_plot(sv, X_exp, feature_names=feature_names, max_display=20, show=False)\n",
    "plt.tight_layout(); plt.savefig(\"shap_summary_plot_mlp.png\"); plt.close()\n",
    "print(\"Saved shap_summary_plot_mlp.png\")\n",
    "\n",
    "# 6. Predictions + error analysis\n",
    "prob, preds = mlp.predict_proba(Xt_test)[:,1], None\n",
    "preds = (prob>=0.5).astype(int)\n",
    "mis_idx = np.where(preds!=y_test)[0]\n",
    "tp_idx  = np.where((preds==1)&(y_test==1))[0]\n",
    "\n",
    "# 7. SHAP local case studies\n",
    "if len(mis_idx)>0:\n",
    "    idx = mis_idx[0] if mis_idx[0]<len(X_exp) else 0\n",
    "    shap.plots._waterfall.waterfall_legacy(explainer.expected_value[1], sv[idx], feature_names=feature_names)\n",
    "    plt.title(\"SHAP Waterfall – Misclassified (MLP)\")\n",
    "    plt.tight_layout(); plt.savefig(\"shap_waterfall_misclassified_mlp.png\"); plt.close()\n",
    "\n",
    "if len(tp_idx)>0:\n",
    "    idx = tp_idx[0] if tp_idx[0]<len(X_exp) else 0\n",
    "    shap.plots._waterfall.waterfall_legacy(explainer.expected_value[1], sv[idx], feature_names=feature_names)\n",
    "    plt.title(\"SHAP Waterfall – True Positive (MLP)\")\n",
    "    plt.tight_layout(); plt.savefig(\"shap_waterfall_truepositive_mlp.png\"); plt.close()\n",
    "\n",
    "print(\"SHAP summary + case study plots saved (MLP).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
